{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90611358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.0.0)/charset_normalizer (2.0.6) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pydicom\n",
    "import torchio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135a89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Adjuvant Chemotherapy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcfe43b",
   "metadata": {},
   "source": [
    "Load image data using PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33fbacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dcm_npy_loader(Dataset):\n",
    "\n",
    "    def __init__(self, img_dir, load, shape=(512, 512)):\n",
    "        self.img_dir = img_dir\n",
    "        self.load = load\n",
    "        self.shape = shape\n",
    "\n",
    "        if not self.load:\n",
    "            load_paths = list()\n",
    "            for (dirpath, dirnames, filenames) in os.walk(img_dir):\n",
    "                load_paths += [os.path.join(dirpath, file) for file in filenames]\n",
    "\n",
    "            ids = np.array([], dtype=np.int8)\n",
    "            img_list = []\n",
    "            num_exceptions = 0\n",
    "            for path in load_paths:\n",
    "                try:\n",
    "                    file = pydicom.dcmread(path)\n",
    "                    if file.pixel_array.shape == self.shape:\n",
    "                        id = file.PatientID\n",
    "                        for c in id:\n",
    "                            if not c.isdigit():\n",
    "                                id = id.replace(c, '')\n",
    "\n",
    "                        ids = np.append(ids, id)\n",
    "\n",
    "                        subject_dict = {\n",
    "                            'one image': torchio.ScalarImage(path),\n",
    "                            'id':id,\n",
    "                            'SliceLocation':file.SliceLocation\n",
    "                        }\n",
    "                        subject = torchio.Subject(subject_dict)\n",
    "\n",
    "                        img_list.append(subject)\n",
    "                except:\n",
    "                    if num_exceptions < 5:\n",
    "                        print(\"Image \" + path + \" could not be loaded\")\n",
    "                    elif num_exceptions == 5:\n",
    "                        print(\"More than 5 exceptions occured\")\n",
    "                    \n",
    "                    num_exceptions = num_exceptions + 1\n",
    "\n",
    "            img_list.sort(key=lambda s: int(s['id']))\n",
    "\n",
    "            ids = set([int(s['id']) for s in img_list])\n",
    "\n",
    "            all_img3d = []\n",
    "            all_ids = []\n",
    "            all_sliceLocs = []\n",
    "            for id in ids:\n",
    "                prev_time_id = time.time()\n",
    "\n",
    "                slices = []\n",
    "                i = 0\n",
    "                for slice in img_list:\n",
    "\n",
    "                    p_id = int(slice['id'])\n",
    "\n",
    "                    if int(p_id) == int(id):\n",
    "                            \n",
    "                        slices.append(slice)\n",
    "\n",
    "                        # remove slices from dataset that have already been appended\n",
    "                        del img_list[i]\n",
    "\n",
    "                    i = i + 1\n",
    "\n",
    "                id_slices = torchio.SubjectsDataset(slices)\n",
    "\n",
    "                # ensure slices are in the correct order\n",
    "                id_slices = sorted(id_slices, key=lambda s: s.SliceLocation)\n",
    "\n",
    "                # create 3D array\n",
    "                img_shape = list(id_slices[0]['one image']['data'].shape)\n",
    "                img_shape.append(len(id_slices))\n",
    "                img3d = np.empty(img_shape, dtype=np.int8)\n",
    "\n",
    "                p_id = id_slices[0]['id']\n",
    "                # get only numbers from patient id\n",
    "                p_id = [int(s) for s in str(p_id) if s.isdigit()]\n",
    "                p_id = int(''.join([str(i) for i in p_id]))\n",
    "\n",
    "                slice_locs = []\n",
    "\n",
    "                # fill 3D array with the images from the files\n",
    "                for i, s in enumerate(id_slices):\n",
    "                    img2d = s['one image']['data']\n",
    "\n",
    "                    slice_locs.append(s['SliceLocation'])\n",
    "                    if list(img2d.shape) == img_shape[:4]:\n",
    "                        img3d[:, :, :, :, i] = img2d\n",
    "\n",
    "                all_ids.append(p_id)\n",
    "                img3d = np.squeeze(img3d)\n",
    "                all_img3d.append(img3d)\n",
    "                all_sliceLocs.append(slice_locs)\n",
    "\n",
    "                aft_time_id = time.time()\n",
    "                id_load_time = aft_time_id - prev_time_id\n",
    "\n",
    "                print(\"id: \" + str(id) + \" has completed \" + \"in \" + str(round(id_load_time,0)) + \" seconds!\")\n",
    "\n",
    "            self.data = [all_img3d, all_ids, all_sliceLocs]\n",
    "\n",
    "            with open('data\\\\Duke-Breast-Cancer-MRI\\\\data', 'wb') as fp:\n",
    "                pickle.dump(self.data, fp)\n",
    "        \n",
    "        else:\n",
    "            with open('data\\\\Duke-Breast-Cancer-MRI\\\\data', 'rb') as fp:\n",
    "                self.data = pickle.load(fp)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = [self.data[0][idx], self.data[1][idx], self.data[2][idx]]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c17cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_numpy_2d(path, clinical_ids):\n",
    "    ds = dcm_npy_loader(path, load=True)\n",
    "\n",
    "    patients = []\n",
    "    ids = []\n",
    "    sliceLocs = []\n",
    "    for sample in ds:\n",
    "        patients.append(sample[0])\n",
    "        ids.append(sample[1])\n",
    "        sliceLocs.append(sample[2])\n",
    "\n",
    "    i = 0\n",
    "    for p in patients:\n",
    "        p_id = ids[i]\n",
    "        if not p_id in clinical_ids:\n",
    "            del patients[i]\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "    slice_locations_min = []\n",
    "    slice_locations_max = []\n",
    "    for sl in sliceLocs:\n",
    "        mi = np.amin(sl)\n",
    "        ma = np.amax(sl)\n",
    "        slice_locations_min.append(mi)\n",
    "        slice_locations_max.append(ma)\n",
    "\n",
    "    # number of intervals to collect for each patient\n",
    "    interval_num = 100\n",
    "\n",
    "    interval_nums = []\n",
    "    all_intervals = []\n",
    "    for ma, mi in zip(slice_locations_max, slice_locations_min):\n",
    "        subinterval_length = int(round((ma-mi)/interval_num, 0))\n",
    "        interval_nums.append(interval_num)\n",
    "\n",
    "        interval_num = min(interval_nums)\n",
    "\n",
    "        # set min slice loc as initial interval marker\n",
    "        intervals = []\n",
    "        interval_marker = mi\n",
    "        for i in range(interval_num):\n",
    "            intervals.append(interval_marker)\n",
    "            interval_marker = interval_marker+subinterval_length*i\n",
    "\n",
    "        all_intervals.append(intervals)\n",
    "\n",
    "    # array to store all intervals\n",
    "    all_interval_imgs = np.empty(shape=(len(ids), len(intervals), 512, 512), dtype=np.float16)\n",
    "\n",
    "    # reshape all patients into (num_slices, res1, res2)\n",
    "    new_patients = []\n",
    "    for patient in patients:\n",
    "        patient = np.reshape(patient, (patient.shape[-1], patient.shape[-2], patient.shape[-3]))\n",
    "        new_patients.append(patient)\n",
    "\n",
    "    patients = new_patients\n",
    "\n",
    "    m = 0\n",
    "    for p_id in ids:\n",
    "        for i in range(len(intervals)):\n",
    "            if i < (len(intervals)-1):\n",
    "                low = intervals[i]\n",
    "                high = intervals[i+1]\n",
    "\n",
    "                interval_imgs = np.empty(shape=(len(intervals), 512, 512), dtype=np.float16)\n",
    "\n",
    "                j = 0\n",
    "                for p in patients:\n",
    "                    id = ids[j]\n",
    "\n",
    "                    k = 0\n",
    "                    if int(id) == int(p_id):\n",
    "\n",
    "                        for s in p:\n",
    "                            slice_location=sliceLocs[j][k]\n",
    "\n",
    "                            if slice_location < high and slice_location > low:\n",
    "                                interval_imgs[i] = s\n",
    "\n",
    "                                # break after adding one image from the interval\n",
    "                                break\n",
    "\n",
    "                            k = k + 1\n",
    "                    \n",
    "                    j = j + 1\n",
    "\n",
    "        m = m + 1\n",
    "\n",
    "    return all_interval_imgs, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8c2894",
   "metadata": {},
   "source": [
    "Load clinical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f77d352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('..\\Clinical and Other Features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9126d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_ids = df[list(df.columns)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "151f4c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array, image_ids = import_numpy_2d(None, clinical_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6d8ad6",
   "metadata": {},
   "source": [
    "Load image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c1c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = pd.read_csv('..\\Imaging_Features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af578b2b",
   "metadata": {},
   "source": [
    "drop ids from image features to prevent duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddf60104",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = image_features.drop('Patient ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee8ebde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, image_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43ce10ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(str(list(df.columns)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bac2d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def tokenize_dataset(pd_dataset):\n",
    "\n",
    "    # replace missing spots with a string then after dataset is encoded, replace with mean of column\n",
    "    df = pd_dataset.fillna('empty')\n",
    "\n",
    "    if df.shape[0] >= df.shape[1]:\n",
    "        long_axis = df.shape[0]\n",
    "        short_axis = df.shape[1]\n",
    "    else:\n",
    "        long_axis = df.shape[1]\n",
    "        short_axis = df.shape[0]\n",
    "\n",
    "    word_list = []\n",
    "    for i in range(long_axis):\n",
    "        for n in range(short_axis):\n",
    "            \n",
    "            if long_axis == df.shape[0]:\n",
    "                data = df.iloc[i, n]\n",
    "            else:\n",
    "                data = df.iloc[n, i]\n",
    "\n",
    "            if str(type(data)) == \"<class 'str'>\":\n",
    "\n",
    "                # list of chars to be removed from data\n",
    "                char_blocked = [' ', '.', '/', '-', '_', '>', '+', ',', ')', '(', '*',\n",
    "                                '=', '?', ':', '[', ']', '#', '!', '\\n', '\\\\', '}',\n",
    "                                '{', ';', '%', '\"']\n",
    "                \n",
    "                for char in char_blocked:\n",
    "                    if char in data:\n",
    "                        data = data.replace(char, '')\n",
    "\n",
    "                data = data.lower()\n",
    "\n",
    "                if long_axis == df.shape[0]:\n",
    "                    df.iloc[i, n] = data\n",
    "                else:\n",
    "                    df.iloc[n, i] = data\n",
    "\n",
    "                word_list.append(data)\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(word_list)\n",
    "    code_dict = tokenizer.word_index\n",
    "\n",
    "    for i in range(long_axis):\n",
    "        for n in range(short_axis):\n",
    "            if long_axis == df.shape[0]:\n",
    "                data = df.iloc[i, n]\n",
    "            else: \n",
    "                data = df.iloc[n, i]\n",
    "\n",
    "            if str(type(data)) == \"<class 'str'>\":\n",
    "                \n",
    "                data = int(code_dict[data])\n",
    "\n",
    "            if long_axis == df.shape[0]: \n",
    "                df.iloc[i, n] = data\n",
    "            else: \n",
    "                df.iloc[n, i] = data\n",
    "\n",
    "    # replace spots previously denoted as 'empty' with mean of column\n",
    "    for column in list(df.columns):\n",
    "        col = df[column].copy()\n",
    "\n",
    "        empty_indices = []\n",
    "\n",
    "        i = 0\n",
    "        for val in col:\n",
    "            if val == code_dict['empty']:\n",
    "                empty_indices.append(i)\n",
    "\n",
    "            i = i + 1\n",
    "\n",
    "        # get series labels at the empty indices for .drop function\n",
    "        col_labels = list(col.index)\n",
    "\n",
    "        empty_labels = []\n",
    "        for index in empty_indices:\n",
    "            empty_labels.append(col_labels[index])\n",
    "\n",
    "        col_without_empty = col.drop(empty_labels)\n",
    "\n",
    "        col_mean = col_without_empty.mean()\n",
    "\n",
    "        i = 0\n",
    "        for val in col:\n",
    "            if val == code_dict['empty']:\n",
    "                col[i] = col_mean\n",
    "\n",
    "            i = i + 1\n",
    "        \n",
    "        df[column] = col\n",
    "\n",
    "    # convert all cols to numeric vals\n",
    "    df = df.astype('int64')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19d57e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tokenize_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc381b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_ids, test_ids = train_test_split(image_ids, test_size=0.2, random_state=84)\n",
    "test_ids, val_ids = train_test_split(test_ids, test_size=0.5, random_state=84)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a3ed45",
   "metadata": {},
   "source": [
    "get patients in clinical data with ids that correspond with image ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "709cdcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.loc[image_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d30d7e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_x = filtered_df.drop(target, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b3e9dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = filtered_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "648b3f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [img_array, clinical_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1d9c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "X_val = []\n",
    "for modality in x:\n",
    "    i_X_train, i_X_test, y_train, y_test = train_test_split(modality, y, test_size=0.2, random_state=84)\n",
    "    \n",
    "    i_X_test, i_X_val = train_test_split(i_X_test, test_size=0.5, random_state=84)\n",
    "    y_test, y_val = train_test_split(y_test, test_size=0.5, random_state=84)\n",
    "    \n",
    "    X_train.append(i_X_train)\n",
    "    X_test.append(i_X_test)\n",
    "    X_val.append(i_X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c1631d",
   "metadata": {},
   "source": [
    "normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9f3e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def four_dim_normalization(img_array):\n",
    "    i = 0\n",
    "    for p in img_array:\n",
    "        s = tf.image.per_image_standardization(p)\n",
    "        img_array[i] = s\n",
    "        i = i + 1\n",
    "        \n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "289c9c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0] = four_dim_normalization(X_train[0])\n",
    "X_test[0] = four_dim_normalization(X_test[0])\n",
    "X_val[0] = four_dim_normalization(X_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42f6eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train[1] = min_max_scaler.fit_transform(X_train[1])\n",
    "X_test[1] = min_max_scaler.fit_transform(X_test[1])\n",
    "X_val[1] = min_max_scaler.fit_transform(X_val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff73f263",
   "metadata": {},
   "source": [
    "Use Isolation Forest to identify and remove outlier patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b2fee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def isolation_forest(features, target):\n",
    "\n",
    "    isolated_forest=IsolationForest(n_estimators=2, n_jobs=-1, random_state=42) \n",
    "    if type(features) == tuple or type(features) == list:\n",
    "        # concatenate features for image clinical\n",
    "        clinical_array = features[0]\n",
    "        image_array = features[1]\n",
    "\n",
    "        new_array = np.empty(shape=(image_array.shape[0], int(image_array.shape[1])**2))\n",
    "        i = 0\n",
    "        for image in image_array:\n",
    "            image = np.reshape(image, (1, int(image_array.shape[1])**2))\n",
    "            new_array[i] = image\n",
    "\n",
    "            i = i + 1\n",
    "        \n",
    "        image_array = new_array\n",
    "\n",
    "        concatenated_array = np.concatenate((clinical_array, image_array), axis=1)\n",
    "        \n",
    "        isolated_forest.fit(concatenated_array, target)\n",
    "        predicted = isolated_forest.predict(concatenated_array)\n",
    "    else:\n",
    "        isolated_forest.fit(features, target)\n",
    "        predicted = isolated_forest.predict(features)\n",
    "\n",
    "    predicted_df = pd.DataFrame(predicted)\n",
    "    predicted_df.to_csv('data_anomaly.csv')\n",
    "\n",
    "    outlier_indices = []\n",
    "    i = 0\n",
    "    for prediction in predicted:\n",
    "        if prediction == -1:\n",
    "            outlier_indices.append(i)\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "\n",
    "    if type(features) == tuple or type(features) == list:\n",
    "        features = concatenated_array\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "    features = pca.fit_transform(features)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle(\"3D PCA of Features with Outliers and Inliers\")\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    ax.scatter(features[:, 0], features[:, 1], zs=features[:, 2], s=4, lw=1, label=\"inliers\", c=\"green\")\n",
    "\n",
    "    ax.scatter(features[outlier_indices,0], features[outlier_indices,1], features[outlier_indices,2], lw=2, s=60, marker='x', c='red', label='outliers')\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "696008b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(X, y):\n",
    "    predicted = isolation_forest(X, y)\n",
    "    \n",
    "    non_outlier_indices = []\n",
    "    i = 0\n",
    "    for prediction in predicted:\n",
    "        if prediction != -1:\n",
    "            non_outlier_indices.append(i)\n",
    "        i = i + 1\n",
    "        \n",
    "    num_outliers = len(predicted) - len(non_outlier_indices)\n",
    "    \n",
    "    print('Num Outliers', num_outliers)\n",
    "    \n",
    "    X = X[non_outlier_indices]\n",
    "    y = y.iloc[non_outlier_indices]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b6d0526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Outliers 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAAEPCAYAAABso1AfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABv/UlEQVR4nO19d3xb5b3+80qWvPfedpzEju04zg6zXHZDIIG0lNEChRa4t9BeRiktt216W0Z7aaGDH22hlMstFEJCoBDKaNgQMj1ix45XvIcsS7Zl7fH+/pDew5GscY50ZDvOeT6ffGJrvOfVsc5zvvP5EkopZMiQIUMqKOZ7AzJkyFhckElFhgwZkkImFRkyZEgKmVRkyJAhKWRSkSFDhqSQSUWGDBmS4rQnFULIvxNCxgghM4SQzPnez0IEIeRHhJCngzx/EyHkk7nck589lBFCKCEkxvP7PwkhN87nnsRCyvPoORdLPT//kRDyYynWFYKQpEII+RshZIQQMk0I6SCEfIv33HmEEJfngpwhhAwSQnYSQtYHWY/98dl7egkh9/OeJ4SQ7xJCWgghRs+aLxNCVvqss8OzzsZwPzwhRAXgNwAuppQmUUonQux1hhDSFO7xfNaMiWSduQSl9CFK6bcA6fbvuYCOEUJMhJBRQsiThJA0Ee/vJYRcGGTPX6aU/m8ke1xIiOS8U0pvp5T+PBr78gchlsrDAMoopSkArgDwC0LIWt7zw5TSJADJADYBaAfwMSHkghDrpnnedy2AnxBCLvU8/lsA3wPwXQAZAJYDeBXAZeyNhBAC4AYAOs//4SIXQByAViF79fxbFcHxIoaHdE9pC5MQcg+AXwL4PoBUuL83pQDeJYSo53lvpwzZRxthnwtKqeB/ACoBjAC42vP7eQAG/bzuDwAOB1ijDAAFEMN77BCAewEsA+AEsCHEPs4FYAZwPYAJAOogr40F8DiAYc+/xz2PLQdg9OxlBsB7QvbKe64KwLtwE9sJdk48z10GoAHANIABADt4z/XzjjkD4AwAOwD8LdBxAXwA4EEAn3o+99IQx98M4DgAA4AhAPcGODd9ANZ6fr7ec8waz++3AHjV8zO3vwD7vwnAJwAeBaAHcBLAlwMcM8Xzvqt9Hk8CMA7gZs/vzwL4Be957rsG4P8AuDznYgbAfQHO2bd4778ZQJtnf28DKOU9RwF8B0CnZ+8EwGMANJ6/4TEAtQE+zzc96xoA9AC4zXfPAO7xrDUC4Ju85zMB/MNzjIMAfg7gEyHXjef8PAFgr+fYBwBU+HympQHO5RYAjQAmAXwGoI73XC+AHwBoBmAFEOP5fchznBMALgh6fQokk/8HwOTZ6FEASSFI5XzPHz0x2Mnx/PHO8qx9AYDbAfQJ2M9fAOwEoIKbVLYHee1/A/gcQA6AbM9J/Hko0gj2PIBEuMnim57PsRqAFkA177yshNsSrAMwBmBboDUhjFT6AdR4jpca4vgjAM7x/JwOYE2Az/ccgHs8P/8ZQDeAf+c9d5cfUvG3/5sA2AF8G4ASwL/DTeDEzzEvBeDwd84B/C+Av4ciFd6X/8IQ5+xbnp+3AugCsMJzvv4LwGc+F+C7cFvG8QAuAXAEQBrc39EVAPIDnMPLAFR4XvcluL/La3h7dsD9HVTBTfYmAOme51+E+3ucCKAW7gtXDKlMANjg+UzPA3gxFKl4visaABs9f6sbPecylndeGwEUe85FJdzftQLePir87ZH9E2RGU0r/A2735hwAr8DNYMEwDPdJTgvyGi3cd9mnAdxPKd0HN3OPBFuYEJIA4KsAXqCU2gHsQnAX6HoA/00p1VBKxwH8DMA3Qux/1l4JIZOef/fCzfS9lNK/UkodlNIGALs9+wKl9ANK6TFKqYtS2gzg73B/4SLBs5TSVkqpA+4LM+Dx4b7AqwkhKZRSPaX0aIA1P+Tt6xy4XV32+5c8zwtFH6X0KUqpE25yyIfbvfRFFgCt53P4YsTzvNS4HcDDlNI2z3EfAlBPCCnlveZhSqmOUmqG+/wlw20NEs/7/H4vKaV7KaXd1I0PAbwD97lksMP9/bNTSt+E27KqJIQoAWwH8BNKqZFS2gL3eRODPZTSg57P9DyAegHvuRXAnyilByilTuqOO1nhdkEZfkcpHfCcCyfcln01IURFKe2llHYHO4Bg39yzgU8AFMF9JwqGQriZcjLIa7IopemU0hWU0t95HpuA+8sYDFfCzf5ven5/HsCXCSHZAV5fALeZz9DneUwMsiilaZ5/j8Lt/2/kEc0k3OSVBwCEkI2EkPcJIeOEkCm4v9SRXiwDvJ+DHh/uL+tmAH2EkA8JIWcEWPNDAOcQQvLhvmvtBHAWIaQMbmuoUcT+RtkPlFKT58ckP6/TAsgK4K/ne56XGqUAfss7Vzq4b3qFvNdw55dS+h7cLvwTADSEkD8TQlL8LUwI+TIh5HNCiM6z9mZ4/60nfAjUBPd5yYbbwuD/XfnfUyEY5f3M1g2FUgD3+Hx3iuF9TfDPRReA/4TbWtUQQl4khAS9fsIJ+MXAbe4Fw5UAjlJKjSLX3gegiBCyLshrboT75PUTQkYBvAy3aXldgNcPw30iGUo8j0WCAQAf8ogmjbqDuIxsX4DbVy6mlKYC+CPcX2LATba+MAJI4P2e5+c1/PcFPT6l9BCldCvcLt+rcJPF7AXdXxgTgDsBfEQpnYb7i3or3Ga4K8Q+wsF+uO+MV/EfJIQkAfgy3N8BIPQ5EbOPAbhjHfzzFU8p/SzQepTS31FK1wKohjv+9n3fRQkhsXBbiI8CyKWUpsF9syO+r/WDcbhvjsW8x0pEfKZwMQDgQZ9zkUAp/TvvNb7n4gVK6dlwX0cU7iB7QAQlFUJIDiHkGkJIEiFESQi5BO5szT4/ryWEkEJCyE8BfAvAjwR9RO/Nd8Idv/m7J12tJoTEefZwPyGkEO7Yyxa4Tb16AKs8HzKQC/R3AP9FCMkmhGQB+AmAv4ndmw/eALCcEPINQojK8289IWSF5/lkADpKqYUQsgHehDcOd7xpCe+xRgDnEkJKCCGpAH4Y7vE95+x6Qkiqxz2c9hwvED4EcAe+cHU+8PndF/72LxiU0im4XdDfE0Iu9ey9DG7iG4Q7CAu4z8lmQkgGISQP7rslH2Mi9vBHAD8khNQAACEklRDy1UAv9pzLjZ6SAyMAC/yfQzXcrsE4AAch5MsALhayIY+b+AqAHYSQBEJINdw3zGjjKQC3ez4fIYQkEkIuI4Qk+3sxIaSSEHK+h0AtcAfHg32fQloqFG5XZxDuqPmjAP6TUvoP3msKCCEsE3AI7gDleZTSdwR8QH/4Lr4wPSfhDh5eCeB1uGMhjZTSdyilo+wfgN8BqCOE1PpZ7xcADsMdzT4Gd6D5F2HuDQBAKTXA/eW5Bm6rZxRuYov1vOQ/APw3IcQAN4nt5L3XBE8mx2N+bqKUvgvgJc8ej8BNGpEc/xsAegkh03C7XtcHWe5DuEnwowC/+x571v6D7TXAGr+C+6bzKNykdwDuO+gFlFIWr/s/AE1wBw7fgfv88PEw3DcLFucKdrw9cJ+fFz3npAVuqygQUuC++PRwuyQTAP7Hz7oGuL+vOz2vvQ5uC1Uo7oDb6h6FO5j6VxHvDQuU0sNwB9T/APeeu+AOtAdCLIBH4HZLR+G2foPe9IgnoitDhgwZkuCULqKSIUPGwoNMKjJkyJAUMqnIkCFDUsikIkOGDEkhk4oMGTIkhUwqMmTIkBQyqciQIUNSyKQiQ4YMSSGTigwZMiSFTCoyZMiQFDKpyJAhQ1LIpCJDhgxJIZOKDBkyJIVMKjJkyJAUMqnIkCFDUsikIkOGDEkhk4oMGTIkxUKcxiZL0cmQEV0IEeYOG7KlIkOGDEkhk4oMGTIkhUwqMmTIkBQyqciQIUNSLMRArQwZgmC32zE4OAiLxTLfW1mQiIuLQ1FREVQq1ZwedyHO/VlwG5KxMHHy5EkkJycjMzMThEQ1oXHKgVKKiYkJGAwGlJeX+z4tZ39kyPAHi8UiE0oAEEKQmZk5L1acTCoyTmnIhBIY83VuZFKRIUOGpJBJRYaMCHDmmWeGfM15552Hw4cPAwA2b96MycnJKO9qfiFnf2TIiACfffaZqNe/+eabol7vdDqhVCpFvWe+IVsqMmREgKSkJADABx98gPPOOw9f+cpXUFVVheuvvx7+MqtlZWXQarUAgL/97W/YsGED6uvrcdttt8HpdHJr3nPPPVi1ahX279+P+++/H9XV1airq8O99947dx8uTMikIkOGRGhoaMDjjz+O48ePo6enB59++mnA17a1teGll17Cp59+isbGRiiVSjz//PMAAKPRiI0bN6KpqQkrVqzAnj170NraiubmZvzXf/3XXH2csCGTiozTCt/Z+x3E/HcMvrP3O5KvvWHDBhQVFUGhUKC+vh69vb0BX7tv3z4cOXIE69evR319Pfbt24eenh4AgFKpxPbt2wEAqampiIuLwy233IJXXnkFCQkJku9basikIuO0wp+O/AlO6sSfjvxJ8rVjY2O5n5VKJRwOR8DXUkpx4403orGxEY2NjThx4gR27NgBwF0Jy+IoMTExOHjwIL7yla/gjTfewKWXXir5vqWGTCqnCZxOJ+x2u18//3TCbWtvg5Iocdva2+Z1HxdccAF27doFjUYDANDpdOjr65v1upmZGUxNTWHz5s147LHH0NTUNNdbFQ05+7PIQSmFw+GAxWKBw+EAIQRKpRIqlQoxMTFQKpWnVQHZE5c9gScue2K+t4Hq6mr84he/wMUXXwyXywWVSoUnnngCpaWlXq8zGAzYunUrLBYLKKX4zW9+M087Fg6592cRw+VywW63w+VyweVycaRCKYXL5UJXVxeWLVuGmJgY7t+pRDJtbW1YsWLFfG9jQSPAOYrqH1i2VBYhKKUwm82w2WyIjY2FQqGAy+UC4C7dJoRAoVDAYDBAoVBwrhEjk5iYGM6SUSgUpwzJyFgYkEllkYFSCrvdjtHRUdhsNn8dql7gkwx7v9Pp9AoyyiQjQwxkUllEcLlcsNlsoJRybo5YMJJh8CUZQoiXuySTjAxfyKSyCMCCsSxmolAooFAoJMn0+CMZh8MBu90OwJ1VcjqdSE1NlUlGBgCZVE55UEphs9ngcrm8CCBaF7YvyczMzGB4eBjLly/nnmfuklKplEnmNIRMKqcw+LUnvhc7IYQLzkYT7LisWIvFdJglQwjxSl/LJLP4IRe/nYJgF67NZgMAvxdqqN/5a0kJRjDsHyEENpsNRqMR09PTmJ6ehslk4qyrOStpCESwc0C8DM8++yyGh4e53xerJIJMKqcYWDCWxU+C3fXnwlIJBUYyLLAbiGRYPU1USOatt4D164GxMe/Hx8bcj7/1lvTH9ANfUuHjzTffRFpamuC1WEfzQoRMKqcIWIDUarXOip/4gxAXI9wMUSTgkwyzsGw2G0ZHR9HR0QGDweBFMhHD5QIeeAA4ehQ4//wviGVszP370aPu58M81m9+8xvU1taitrYWjz/+OHp7e1FbW8s9/+ijj2LHjh3YtWsXDh8+jOuvvx719fUwm81e6ywmSQSZVE4BMEI5cuQIl90JRRpCCGO+Yxv8eIzT6eREmoNZMqKhUABvvglUVwPHj7uJ5Ngx9//Hj7sff/NN9+tE4siRI/jrX/+KAwcO4PPPP8dTTz0FvV7v97Vf+cpXsG7dOjz//PNobGxEfHy839ctBkkEOVC7wMGvPTGZTIKJQKgVslDaNPjBZn7Ql2W3+PEjFvgVvPfcXOC9974gkro69+PV1e7Hc3PD2vMnn3yCK6+8EomJiQCAq666Ch9//HFYazHwJREAwGw2IycnB0BgSYQtW7Zgy5YtER1XSsikskDBis5Y+bxC5J1UqKUiBalEi5j81chQSmG1WmG1WrlzxE+jByTd3FzgxRe/IBTA/XuYhBIIk5OTXhaV2BEZTBLh4YcfnvWcP0mEffv2YdeuXfjDH/6A9957L7LNSwTZ/VmAYHdnRii+F5YQzFW8RCoXilkqoY6lUCi4zBJ7H2uYZIV4TqdzdtB3bAy45hrvBa+5ZnbwVgTOOeccvPrqqzCZTDAajdizZw++/OUvQ6PRYGJiAlarFW+88Qb3+uTkZBgMhqBrLgZJBNlSWWDwLbX3rT0RcvHxXxvpaxY6fM+Fy+WCxWLhYhaEEBCNBuTCC0FYDOXFF92EwmIsYbpAa9aswU033YQNGzYAAL71rW9h/fr1+MlPfoINGzagsLAQVVVV3Otvuukm3H777YiPj8f+/fv9rrkYJBFk6YMFAt9Se3/E8fnnn2P9+vWC1NWnp6fR19eHlStXwuVy4cSJEzAYDMjIyEB6ejqSkpLQ2NiI2traiGbtGgwGDA4ORixBoNFoYDQaQzZA8tHf3+910QJfdGgz2UXqdEK5aRNIQwNodTVc774LkpcHotEAF1zgJpo1a4BDh8IK1i50zIf0weI7i6cgmLsTqvZEjGXBXmsymXDw4EHExcVx2in9/f04ePAgjEYjhoeHYTKZFoTFIoUr5WvJEaUSrp//HHTNGrjefRc0J8ftKmVlwfnOO+7Hf/5z0EVgtS0UyO7PPIPfnBeq9oSvixIKhBCYTCY0NDSgpqYGKSkpsNlsSExMREFBASilOHr0KCil6OrqgsViQVJSEtLT05GRkeGlt3rK49JL4br4YkCh8L5F5+XBuX+/20Lx1IKwv0G0e6gWM2RSmSdQSmEwGLzK2UNBqKXicrnQ09MDs9mMs88+GyqVahYZsZ6c/Px8lJWVcfvR6/U4fvw4HA4HUlJSkJ6ejvT09IhcJCEQGisK+30BXBvi40qyDBPwxSAvfl3QqUQy82V5yaQyD2Ayj62traiqqhI8dkGIpWIymdDc3IzMzEykpqaGJAP2xSOEICUlBSkpKSgtLYXL5cLU1BT0ej0GBgZAKUVaWhrS09ORlpYm+dS8cEhFrVZDp9MhIyNDsoudvw5zR32fPxUsGUopJiYmEBcXN+fHlkllDsGvPQEgWvMklKUyOjqK7u5u1NTUIDY2Fm1tbWGvp1AoOCsFcF9gk5OT0Ol0OHnyJPd8bGzsvN0Rs7KyoNVqMT4+zj3GAt5SWFZ2u53rVwqGhUowcXFxKCoqmvPjyqQyR2CdxaxYi9VciCk9D0QCLLtjNpuxYcMGqFQqLtUoFWJiYpCVlYWsrCwA7lL6yclJjI2NQa/Xo7Gx0SuzJPYCC8dSiYmJQV5entdjLBtVUVEhai1/aG1tRVlZGVcx6wvmKvGtPVkVTyaVOUGg2hOxpOLv9czdycvLQ1VVldddM5p1Kmq1Gjk5OYiPj0dMTAzKy8s5V2lmZgbx8fGcpZOQkDBnF1e4sRl/cLlcQSuZQ6nina4kI5NKFOFP5pGPSN2fsbExdHV1oaamZlbb/FwXtsXFxSE/Px/5+flcKluv16OnpwcmkwnJyckcyfjz86UiAylJhVIqqj3CH8kwwaqTJ0+ivLwcKpVq0aviyaQSJQSSeeRDrDobIwp/7k6g1wpZT2oQQpCYmIjExEQUFRWBUoqZmRnodDq0t7fDZrMhNTU1KpklqS2VSNbiN0fq9XpUVFScFqp4MqlEAcw68Vdqz0c47o/JZEJbW9ssd8cXC6lMnxCC5ORkJCcnc5ml6elp6HQ6DA4OwuVyQalUIiEhAQ6HAzEx4X8t59L9EQs+yQBf3HisVisA7w5sFiA+FUlGJhUJEcrd8YVYUjGbzdBqtairqwupEuaPMBbKF1ShUCAtLY37DA6HAz09PTAajWhsbAQhhLNiUlNTRV3YUrs/0TxnwUiGEQrfXTpVSEYmFYngcrmg0WiQmpoq+I8vNKbC3B2j0YjKykpBsoMLyVIJhZiYGCQkJCAxMRGFhYWw2+3Q6/XQaDTo7OyEWq3mSCY5OTnouV3Ilkoo+GrJAJilJeM7qWAhQiaVCMGvPTl+/DjOOusswe8VU8yWl5eH3NxcwV+kuSQMqY7DyEClUiEnJ4cTJ7JYLNDr9RgcHAyZWZLaupgvy4Ad1x/JtLS0YMmSJVCr1QuSZGRSiQD+ak/EIFSg1je709nZKSlRSEE8UroageCbWTKbzVxmyWw2IzExketZktr9WSjr8EnGaDRycSdmyezfvx/Hjx/HPffcE/GxIoVMKmHCX+0JIwmhd4xAlgo/u7N+/Xqo1Wru9WK6lH0xq4N3gbg/DEL7nxISEpCQkIDCwkIus6TX6zkXUaVSISEhAenp6dy5m09I7UaxVDffXZqYmAgpADVXkElFJIIFYxlJsMdIczOgUoH66lno9SCHD0NRVQWXz0UdqJgNiGxAGEtFLxQTWSrwM0slJSUYGRnhxLKHhobgdDq9epbEZJYWcmzGd28zMzMBK3/nGjKpiECo2hMvy2N4GIpduwCFAq6vfe0LYtHroXzmGWByEglGI6br67n3BytmA8K3LOx2O44dO8bdxZmrwD7TQoCUbktCQgKKi4tRXl4Op9OJyclJ6PV69Pb2emWWUlJSJG+M9AeWMo8mjEYjkpKSonoMoZBJRSCCjRhl8CKV/HzQM88E+fRTKF56yU0seXkcodCSEljr6zl9VX/uji/CsVSmp6fR0tKC8vJyZGRkcJmV4eFhaLVazMzMIDc3d87L6aMFX3JSKpXIzMxEZmYmADfBTk5OQqPRoKurCzExMRzJhsoshQun0xl1C9FoNCJXYhHvcCGTSgiIqT1RKpVfXPSEwHXJJW5pvU8/Qfcffgazw4zKzEqoy5fBdcMNUExOwqrT4eDBgyGL2QDxZf0sU1BXV4fExETYbDao1Wrk5uYiNzcXHR0dSE5OhtPp5MrpmYZKRkbGnMYj5qpMX6VSITs7G9nZ2QAAq9UKvV6PoaEhGAwGxMXFcZaMVBMepXR/Av39TSaTbKmcCmC6J0ImAgLui95rHKWHWEb7W9HW0QYKCrVSjWU3/ByIjcX09DRGRkawZs0ayWpPAPedsa2tDU6nExs2bAg4I0ehUCA2NhYZGRkoKiqCy+XihJpaWlrgdDq5CywaGip8SEkqYi7g2NhY5OXlIS8vzyuz1NvbC7PZjNbWVu4cBBoAFgpSkkqgtYxGoxxTWciglMJiscBut0OlUokqZpt1d5ucROrEDNRKNewuO1LUKaBdXWhXKDA1NYW8vDzBM3QVCgXXNxIILNBbUFCAqakpr8BkqAtXoVAgNTUVqampKCsrg8PhwNTUFHQ6HXp6eubEVYgUkZATP7OUn5+PI0eOoKSkBHq9Hh0dHbBarV5qeEItOSlJhanR+WJmZka2VBYqmLvDMgdlZWWC3zuLVDxB2SSTA+ecfT3MGSlIberE2OOPI/VrX0PO6tXcfBchCGWpsApUFugdHByc9X4x68XExHjFI5irMDg4CIPBwFXBOhwOwZ8hEBZalzIjAn5miVlyOp2O+36kpqYiIyMjaGYpEBGEg0Brye7PAgW/9kSpVIq+WLxIhZfloSUliLvhBkzp9egYfgFLnU7EfvIJJlNS4BJhsgYiAUopOjs7MT09HTTQK3S9QPB1FUwmE0ZGRmAwGHDw4EGkpKRwQk3R1rQNhGi6UXxLjmWWmOQmyyyx9HVqaip38c+V+5OcnCzJMSKFTCrwP2KUDQ0XA69AbWwsaHw8kJICx9e/jhOe6s/a73wH6vffBw4fBklOBhVxDH/uldVqRXNzM9LT07F27do5c0mYvEFeXh5sNhuqqqq4zmO+pm1GRobXBRYIC9VSCQalUomMjAwuPc8yS1qtFt3d3Zy7KGW6PJClIsdUFhAC1Z6EQypegdqEBLhuugkmqxXNTU3Izc3lsjuuSy4BNm4EVCq4enoEr+9rWTDl++XLl3PZDDGQsqLWX+ex7wXGLsBw5CaFQkpSEbtOsMyS2WzG9PQ0F49JTEwMa5/BSEW2VBYAgo0YFStL4O89YwaD/2I2QoD0dBCjMSyRJkop+vr6MDo6ijVr1oSdlYgmfDVtWVNgf38/V/3JXKX4+HhJ+2zmI4vkD8xddDgcnFC4TqdDb28vZ1mwwLfQv2EgUrHb7QtmVtNpSSpCak/CtVTEFLOFI9LkcDjQ1NQEtVqNDRs2RPTFn8veH9+mQKPRCJ1Ox2VV2H6EjBUJhrl0f8SsFRMTg/j4eBQWFnI9S0ajEXq9Hp2dnbBYLF6Sm4EIIhCpLJTKaOA0JBUhMo9A+KRisVhw6NAh5OTkSF7MZjabMTo6iqqqKhQUFIjamz/MV0MhIQRJSUlISkrisirHjx/n0uEAvOIx8yHSFG1dFv45KC4u9qoRYsPcmORmWloaR7T+SGUhEQpwmpFKtEaMMszMzGB0dBSrV68WVHsi5hjDw8Po6elBRkaGKEKJtnoZO0YkUCgUiIuL42Iu/FL6zs5OxMbGcm5CqFjEQrVUhKgA8muE+Jml/v5+UEqRnp4Oh8MRMCC7UOqGTgtS8XV3hJx8MZYKc3f0ej0KCwsFF7MJ6eVxuVxob2+H1WpFTU0NRkZGBK3N1g92kS0kPRU+fAOe/CpX1jjHCMjXTZAiFgLMTcFaMPhmlljgu6+vDxMTE9BoNBzRMpGmcEAIeQbAFgAaSmmt57EMAC8BKAPQC+BqSqle6JqLqw/eD5jMY39/vyghJaGkYjKZcOjQIcTFxaGiokLURRbKUjGbzTh06BASEhJQX18PlUoV0UgPsc/PJYKRX3x8PAoKClBbW4sNGzagpKQENpsNx48fx6FDh9DR0QGtVuslNh7N/YiFFATFAt/p6elYvnw5amtrkZCQgK6uLpx11lkYGxvDY489htbWVrFLPwvgUp/H7gewj1K6DMA+z+/C9yp2B6cK+LUndrsdRqNR0gse+EKqoLq6Gunp6dBqtZJMHAQArVaLEydOcGuzPUlJKqci+PoppaWlswrQ2GRGl8uFlJSUsC/muXZ/hIJZPfzG0L179+LWW29FSkoK3n77bdTU1Ahej1L6ESGkzOfhrQDO8/z8vwA+APADoWsuSlLxlXmMiYkJK+ga6IJk7o7JZJqlzCaWVPztvbu7G3q9HuvWrfMy78VKH/BJxWQy4eTJk1xZOetpWiikE65l4OsmtLS0ICEhAaOjo+jo6OC6jjMyMkRJOyx0UuHDZDIhOzsbt9xyiyTHAJBLKWV+9igAUZoKi45U/NWehEMqgWA2m9Hc3Ow3u+NVURsGbDYbjh07huTkZKxdu9ZvxiAcS2V8fBwdHR0oKSmByWTC4OAgKKWIiYlBUlLSglGEk8LdIIQgMzMTJSUlAOB3UiKrjwlW1xHpIDE+ot37E03VN0opJYSIuvMsGlIJVnsSTnrYH1g2gu+S8DFL+kAEpqam0NLSgmXLlnEq8v7WF0tavb29mJqawrp16wC4L7ry8nLY7XZ0d3djamoKhw8f9sq+JCQkhPUZIkG0it989WxZQyBL27LUta+0g1QBX0B6S8V3rSiQyhghJJ9SOkIIyQcgvOsVi4RUQtWeREoqLpcLHR0dMBqNkhazsb339/djaGgIq1evDnpBi7FUHA4H10nMeoLY/BjAnWFJSUlBUlISCgsLYTabodPp0NXVBYvFwrlJ6enpEU0MFINoB1gJIUhJSUFKSgqXtmVSkydPnuSqXjMyMiRVa4u2+xMFKcl/ALgRwCOe/18T8+ZTnlSEjBgNp+OYge/uVFZWSlrb4nA4YLFYMD09jQ0bNoQ0kYWSyszMDJqbmxEbG4uKioqQAV6+jggTa2I6Kn19fSCEcFZMSkpKVNLI81Gm7ys1abPZoNPpMDw8jImJCajValBKuTL6cD+31PEZfzGVcPt+CCF/hzsom0UIGQTwU7jJZCch5BYAfQCuFrPmKU0qrJhNlMyjCNjtdhw9ejSgu+MLMaRiNBrR3NwMpVKJ2tpaQe8RmpHq7u7GypUr0dXV5fV6oXoq7I7NPrPNZuN0bdvb27m+HRYclQILIRWsVqs5aYe+vj7ucWa98eMxYqQ2o+1KGY3GsF1WSum1AZ66IKwFcYqTChC6Mpa9RsydkLk7DocD69evF/wHE0peo6Oj6OnpQW1tLVpaWgTvK9jnYJoqBoMB69evl1TPhJ++ZDoqExMTaG9v51K4Wq1W9AiMaEBKckpISEBOTo6X1CYTaHK5XKKkHaSE7+ebmZlBSkrKnB0/FE5pUhFTzCYUfHcnOTlZ1EUSKlDLyIqlotmFL/RCCEQqNpsNzc3NSE1NxZo1a7i1olH8xnRUEhMTUVJSAoPBgM7OTkxOTuLkyZOchkhmZqYoiYOF2KXs27XOF2hiFa4TExNe2inzIbVpNBpRWFg4Z8cLhVOaVKSGb3ZHr9eLCvAGu0gtFguam5uRlZXlFZth8Y5wSYWN4Fi6dOmsrNFcVNQy8eylS5cCcGuI6HQ6TuIgWEm9v/1Eirnq/fGVdmCfm0lt8mUNoo2FJCUJnOKkImUZtb/sjtgUcaD9MFehqqqKCwoy+E41FLP+8PAwent7sWrVKr8pRV/SmIvmwtjYWC+Jg5mZGa8ULrvQouUyzJdIk+/nNplMnLSD0WhEe3t7xFKbgW4AC0n1DTjFSUUMAjXXBcvuRFrMRinFyZMnMT4+jrVr1yIuLs7vvsQeg1X0WiwWbgSHP8x374+/knq+GpxKpeKsGKmKzRaCSBPfRSwqKsKhQ4eQl5fnJbXJH30i9DiBPttCmk4InEakwqwO/gUYqpgtkvoWNmo0ISEB69evD/jFEZuGdrlcOHz4MLKyskLqtcw3qfjCN4VrsVg4JTSdTgeXy4WcnJyIBpktNOkDRk6+Upt6vX4WuaanpweNQwWTkpRJRSKI+fKwUv2YmJioFrMBX8Q5lixZgry8vKCvFXOMyclJmEwmVFVVcb58MPgjjWi4QOESU1xcHAoKClBQUIBjx44hNzcXRqMRLS0tcLlcXq6SmAt8PtyfYOv47j0mJsZL2oGRKz8OxT4737qVSWWBgVkdYorZwrFUbDYbWltbA8Y5fCG083hgYACDg4NISEgQRCiAN6mwTBn/WAtJT4V4lNBycnK47Iper/cSasrMzIy4EE0opNRlCRU74pMrX2qzvb0dNpuNq25Wq9UyqSwkKJVKjI+PY3BwUHAxmxhS4Y8aXbduneBgXKiYCpNadLlc2LBhAw4cOCBoXbb2QulCDgVfC8r3bs4Cn6wQLdozhqRyf8SW+zNy5UttsupmrVYLu92Onp4ebraQQqGQjFQIIb0ADACcAByU0nXhrHNKk4qYNvbp6emQ7o4vhLomJpMJTU1NKCwsxPT0tKisRrBjWCwWNDU1IS8vDyUlJaLvzgstphIJfNsI+DOGAHC1MVLWuywEBTl+dXNGRgY0Gg2SkpI4C+6Pf/wjnE4nN5lSAgvu3yil2kgWOKVJRQiYuxMTE4MlS5aICgAKsVTYH7e2thapqakYGRkR9UUKRCo6nQ5tbW1YsWJF2LUOfNKglEKj0SA+Pp4LBi4kUhET6/ENfNrtdq6NwGQy4dixY1xWKZKh6gsp4MvWiomJQU5ODleTlJKSghtvvBE///nPMTQ0hI8//nhOC+/84ZQnlWAXBj+7MzExITroqlQqufERvnC5XOjq6uLK4sMVavKNqVDPTJ+xsbGAaWihYOfG4XDg2LFjXGOl0WhESkoKYmNjI0qZS41wLwaVSsVdaAaDAUuWLPEa/5GamorMzExRbQRSkYGQmIpQ+AvUVlZWQq1W46WXXpIiCE8BvOPRT/kTpfTP4SxyypOKP/jL7kxOToY9x8cX/FGj/LJ4QHxtCz+m4nQ60dLSgpiYmKBpaDFrs5EhpaWlyMrKAvUMIzMYDBgaGoJOp8PMzAx3Z5/rEnMGqSwmfo0IG30xNTWFiYkJ9Pb2QqFQCPqsUmXJpJRQCJT94bdlRIizKaVDhJAcAO8SQtoppR+JXWTRkUqg7E64s5F938PmslRWVvrNwoitwmXExeIyxcXFKCoqCvj6QEV8/mA2mzE8PIz6+nqkpqZyeiqsj8XlckGlUqG0tNSrxDwpKYnLtIRbL7JQ4K/j2recPiMjA5mZmV5tBFJaKtEkFTb9UApQSoc8/2sIIXsAbABw+pEK3/0JVsymVCq5mT9CwScIvlsSbNRoOO7P5OSkV1wmGJhlE8ykZnvV6/VYsmRJwDXZueO3/LPS+omJCa5ehF10ycnJUZOdnIsWAgCzPitL3/oqwS20IjrATSq+mS6pSvQJIYkAFJRSg+fniwH8dzhrnfKkAghTZlMqlbBYLKLWZa6Mw+FAS0sL1Gp1SLdEDKlQSqHX67lyeyFWQajgqtPpRGtrK5RKJYqKioLGEPytxS+tLysrg8PhgE6nw8jICE6cOIGEhAS/d/ZIMR8BY9/0LWsj0Ol0MJlMaGho4Cw2qQeqh4NA+rQS1ajkAtjj+YwxAF6glL4VzkKnPKmYzWY0NjaGLGYL1/2xWCw4ePAgysrKBE0GFEoqLHjqcrlQVlYmSZqbpaDz8/NRUlKCkydPRnyx8rMN/u7sSUlJnJSnFDGg+QS/jUCv13MBfjbEjIk0iXELo61PK1WHMqW0B8CqiBfCIiCVoaEhLF++PGQxWziK+lqtFnq9Hps2bRL8hxMSqGVyj0yAOhyFfF9MTk6itbXVKwUtdZ2Kvzv76OgoJicnvcSzMzMzw07lRoJZn4VSwB9RBXqcB0IIYmNjvSpdmUgTcwv5otmBiIOlgaWAP7c3mkr64eKUJ5Vly5YJIguxY0zb29thNpuRmpoq6k4QKlDLl3tMTk7G4OBgxJotg4ODGBwc9BvrCVaWH2mdilKp5HRnamtrvdr9rVYr0tLSuFRuKBdA6piK4sQJwGCAa80agH/BT0xA2dIC59q1gIi/KyHeotlMpEmr1aKrqwuxsbFe0wjYZ4l2oFYmlXmEUPFrlj3Kzc3F0qVL0dTUJOo4gdyTQHKPCoVCVACZvz6TQLDZbFi/fv2sL5zYiYaRgl/1yiYHTkxMoKenByqViotPiBnqJQYcMVksIP39gMMBxdGjXxDLxASUhw8DLhcUg4NwVVWFfSxfkSY2jYDNF0pJSUFmZibsdrtkI0/mSEk/YpxWpBLKImBDt1j2yOl0SlLbwoaEpaSkzKprCXeUqc1mQ1NTEzIzM4NKIMxXmb7v5EDWidvT0wOz2cxddGwEiBSWCrdGXBycGzdCeeAAyPg4FEePwllagpijDYDLBVpYCFdlpRQfk0N8fDwKCwtRWFjI6dlOTExgbGwMExMTMBgM3DSCcC2XQNMJZVKRGEK/iMFIhVL/o0bDkT7wfU8wuUe2f7HFcjMzM+ju7sayZcu4hjshe5lP8DtxWe/OxMQE+vr6oFAoYLVaOQHncMnFi5hSUuDcuBHk8/1oOvY2dAd1WJW7CpnL6uFauTJoTEUKiU2mZ+twODgRKv4o1nAGtwWyVGT3Z54QiFSYaHRKSgrWrVvn9YUO58vND9Qyuce6urqAdxOxF77VakVHRwdWr14t6A4VbG2pLBWxa/j27thsNhw+fBgDAwNcloW5SmI6kGdZOykpmC7Jg6ZDA7VSjWHDMNJrrg8ZpJUyvuNyuaBWq5GSksJl0MId3OYvPjMzMzNLonS+cdqQij83g2VMgo0aDec4NpsNbW1tIeUe2euFkAqlFF1dXTCZTFi5cqUgQgl1YSwUPRW1Wg21Wo3q6moQQjjXYXBwEAC8iu+CHW9WZ/HEBFL7RlCcUgydRYeS1BIoGhpmB299IOUcZV8iICT44DZWARzo8/r+bjKZUFpaKslepcIpTyrh/PEppRgYGBA0alQsnE4nBgYGUFxcHFLuERAWU3E4HGhubkZSUhKys7MFF1MtpC7kUGDWAT/LwlLubNbO9PR0UHV+LwuDC8pSrKi/GK7SUigPHgQ8MZZgxCKV7AEQuvhNaBtBoE512f1ZAHA4HDh+/DgUCoWgUaNiMDk5iZ6eHqSlpWHJkiWC3hMqpmI0GtHU1ITy8nLk5+ejra1NsLu0GPRUVCqV1yAzo9GIiYkJHD9+HE6n00tykrMwLBYuy0MLC7kYilfwtq0Nrpoav8eUWq5AzFqB2gja29thNBrR0dHBuUpKpVJKgaZLAfwWgBLA05TSR8Jd67QiFafTiUOHDoVs2vOFEB97cHAQAwMDWLp0KWZmZgSvHcz90Wq1OHHiBFauXMlNoBNDBL6vHR8fByEE6enpUevhCRdCzjG/+K60tHSW5KRarYbdbocFQPzy5SAGg3dQ1hO8Vba2wlVREfA480kqfPgWGx48eBBZWVnQ6XQ4efIk9u7di87OTgwPD0d6HCWAJwBcBGAQwCFCyD8opcfDWe+UJxWh7s/o6CjMZjM2btwYsmnPd/1gX3hfucfp6WlMT08LXt8fqVBK0dvbi/Hxca9sFNuPWEuF1bOYzWaoVCp0d3cjLi6Oy06cquBLTlJKMTExgZMnT6K9vR12u91dfKfXe88YSkmB84wzgq4rdaBWym5nviuUm5uLO++8E3//+9/xyCOP4K233gp3UuEGAF2eUn0QQl4EsBXA6UkqocC/oBjriwHLGvn7YviTewxH+oBvTbCGwJiYGKxbt27WccXUtRBC4HA4cPToUaSnp6OiooJ7r9lsxtjYGGZmZnDo0CEuOChWuX6hgBCCuLg4JCYmorq62mvGEKt45RffBcNCsVT48BebKSkpgVqtxpNPPonCwsJIiLAQwADv90EAG8NdbFGTCrvoc3JyUFVVhcOHD4vuGmWk4pvaDCT3KDZFzLc8LBYLGhsbUVhYiOLi4oCvF0oqVqsVw8PDqK6uRl5eHpxOJxwOB5eBKCgowPT0NGpqajA5Ocm5EQkJCdwFKGUncrTBtzB8Zwz5S+Oy4jvf74PULQNSSSgEUtKPpiRFODjlSSXQH4yNGuVf9DExMXA4HKKEh3xJIpTcYzh6Ki6XixN/CqX0L9RSYeXxWVlZ3OwhfzIHlFKvknN+MLS1tdVLTyWSwrS5QDAy8K14ZS0EbKg8X+JASktFKgSylk0mkxTZnyEA/LtYkeexsHDKk4ovqGfUqFarnXXRR6r+xtcqCaSrEg6pmM1mnDhxIqj4E4OQmEp/fz9GRkZQWVmJyclJAO7z4nQ6YbfbubqZQHoqvsFQnU6H4eFhtLe3R00VLiRZCeg4Fmph+KZxrVYrJ3FgMpk468xut0dl/Ec4CGRh+07dDBOHACwjhJTDTSbXALgu3MUWBamwi4M/atRfPCISUhEq9yiGVJi4lN1ux5lnninILQvm/rDuarvdjnXr1mFqaorTpHW5XFz9BTsHTHYh2J3ZV0+FqcIdO3YMAJCcnMytEy0rJub55xHz7ruwPPUUwLvISXc34m+/HeY//xm0vDzsPfAlDlwuF4aGhjA2Nobm5mYQQuZdvxfwTyoSjiNxEELuAPA23CnlZyilreGutyhIBfiix6aiogK5ubl+XxMOqSgUCm78gxC5R6HHYA2BbLSl0DhPIPfHbrejqakJ6enpWLFiBVdIxiwU5uYwS4fNiklJSeEaJ1mgORDB+KrC2e12jI6OYnx8HAcPHgy7vD4o9HrE/fCHIJOTAKWwPP00oFKBdHcj4bLLoBgeRuzPfw7LM89IQmwKhQLx8fHIyMjAkiVLZhWjhSPUJAWCxQKlIDpK6ZsA3ox4ISwSUhkYGMDAwEDIUaNiSYVSyg2t8k3tBoIQS2V6ehrHjh3D8uXLkZ2djbGxMcF78uf+sAI5f4Q6MzPDaW6wLx+r0M3JyeGm4DmdTu5/do4UCgVHNP6gUqmQlZWFyclJ1NbWepXXszt8ZmZm0KHjIZGeDtMrryBh2zao9uwBANgeeADxV1wBxfAwHGeeCcvvfgcgOsPZI9HvlbKwMJSS/kLCoiAVodWxYkiFyT1SSrFkyRLBWZBQ2ZnR0VH09PSgvr4+rACbL6mwgDS/QA5wfwkTExORm5uL7u5uWCwWpKWlITk5Gf39/Vi2bBmnBcK3TpibxEiGrSXEiuGX19tsNq4Lmc0ZysrKCtk05w+udetgevVVjlgYuTjOPBPmXbs4sSUpScXfOv4sNWbFTk9Pz1Lmj7ZAk81mk0xVTkosvB2FAdaYFQpCSYXJPZaVlcFqtYrWO/EH1hA4PT0dsskwGPiiTiwgy7eiWIyEfaGLioq489PX14fOzk6oVCoMDg7CYrEgKyvLK5jNLgL2BWbWCyMa9rNSqQx6AavVauTn5yM/P5/TF9Fqtejr6/NK9woVbHKtW4e+n/8AZd97gHvM/OKLXuptUpGK0N4f/hAzf/q9qampHDlHSi7+sj8Lse8HWCSkIhRCSMVX7rG/v190HMYX/IZAX5EmsWCWCvvirlu3jiMAPqGwmArD8PAwtFotzjjjDMTGxsJoNEKr1aK1tRUOhwOZmZnIyspCamrqLBGpYFaM3W73IjF/4OuLAF9kW5hgE6vsDRo36O5GyS//4PVY3Pe+x8VY2OeX2v0RCn/6vWNjY9BqtZLo9zIJBT4kVNKXFIuCVMQINbGBWr7gWxK+co+RlLL7NgRGCqfTiaGhIRQVFaG8vJz77PyALJ9QKKXo6OiAzWbDmjVruIuWTfHjp42HhobQ1taGpKQkrm6FH3D1tWJsNht6enqQmZkpKhbjm22ZmprC+Pg4jh49yslOMisGAC8oOwLHmWdi5r57kHrDNzk3iBHLXFsqwaBUKpGWloaUlJSI9XuBU0f1DVgkpCIUgSwVu93OCTX5G2MaiIhCgclT+sY7woXRaER3dzdSU1O9uqADEQqLC6WkpGD58uUBLzjftDFzVRobGwGAIxh+wNVisaC5uRmlpaXIzc0NGIsJRTCsZiQ2Nhbr16+HxWLBxMQEV/maqVCg9rrroBgd5WIoyqQkrxgLTUmB9fe/l7TPRopYBX8/ker3BlJ9k1K2QyqcdqTia3UYDAYcO3YsYCo6nDQ0vwAv0HAzsWAdyyzOw8BiHgC8Ligm4F1aWspV1AoBP+DKUqparRYnT56E0WjkpgsMDg6iurqaU2/jWzF8UmGuEdujUqn0e+GzuFVcXJxX5evk5CQ0V16J+E8+QdtPf4r0yUlkKpWI9wRv47/5Tdi/+U1ujflyfwKt488K8affy3cHffV7gagPEpMUi4JUhH6RfGf/jIyM4OTJk5LKPTqdTlgsFpjNZqxdu1aSL2dfXx9GR0exbt06GAwGWCyWoPGTqakpHD9+HCtWrOAu+nChVqu9XJX+/n6cPHkSarWaawPIysryumOyz8yPxfDT1ULdJNaVi1/+ErDZUOFx05g7l5aWhsx330VaTg4UkDZQK8U6Qoez+xKpr35vZmYmLBaL30CtTCrzDGZ1sEpWs9kcMhMjxlJhDYExMTGoqqoSRSj+vsgulwttbW1wOp1cW4DRaOQuUn+EMjo6ir6+PtTX10s+0Isf7FWr1TCbzZwFZbVakZGRgaysrFnDtViwNyYmhnOT+NaLw+EIWdkLtRoJarWXCzE5OQntxAS6+vu5AkIpsiFSyxWIga9+r9VqhU6nw8zMDFpbWzkrJiMjQ/LsDyFkB4BvAxj3PPQjT1GcKJx2pGK323HkyBFkZmYGHZPKf48QUuE3BHZ0dIj6QjFriG/esorbrKwslJWVee3TZrN5xSuAL1yuqakprF27VtL6BRbENpvNWL16NbfP+Ph4FBcXo7i4GE6nEzqdDhqNhpu5zKwYfo0P301SqVRwOp3o6Ojg0q++KetA55CflqaUwmQyoaenh6vw5TdBir2wpdKolYKcYmNjkZ+fD41Gg8rKSq7+Z+fOnXjuuedQXl6OgwcPYu3atVKpGD5GKX00kgVOK1IxGo3Q6/VYvXo1V/gVCkLcH6Z3yxoYhYw+9T0GvxaG1cn4jvWglHJuxsGDB7mCsrS0NHR0dECtVqO+vl7SKkuXy4XW1lbExsZi5cqVAddWKpVegkksZc3mRbOUNb/Tma2dkJDAab2EW3iXmJiItLQ0ZGVlITs7G3q9nhuJIVbKQSqNWqmHs8fExCAuLg4pKSm48847YbVaodFo8Mc//hFXX301Lr30UkmOFSkWBakIuYiY3CO7gwpFMEuFNfA5HA6vCYHhCDWxi4i5E3V1dUhOTuZeQymFw+GAUqlEbW0tKKWYmprC2NgYWltbERcXh6KiIlgsFsncHtZPlJubG1DfxR/4NRus8nRiYgIDAwNc/0x6ejqGh4eRl5fHrc3XQgFCF975K4snhMxShBMr5TCf7k8g+CMol8uFf/u3f8PVV18tyTE8uIMQcgOAwwDuoZTqxS6wKEglGHzjEgcPHhT1/mDzghobG5GdnT3LPQlHqMnpdHI6LfyMUaCALLt49Ho9Vq1ahYSEBGi1WrS3t8NqtXoVs4XzxTaZTGhubkZFRUXQgWVCoFKpvPpntFotjh8/jpiYGIyNjcHpdCIrK8urPwkIXXjncDi41zBrz5ckwpFyWIikAsy+eYYTU7nwwguxb9++Fj9PPQDgSQA/B0A9//8awM1i97moSYUpv+Xm5qK0tDQst8AfQfg2BAp5TzAQQtDR0QGFQuEl2RAsw8NkEmtra7kMgG98Y2RkhLtwsrOzkZmZKah7eHJyEm1tbaipqZGkvoYPo9GIrq4u1NXVIT09HVarFVqtFt3d3TCZTEhPT+d6hPh35kDtA/yskpCAbygph4yMjLDrknwhVb1LIIST/fnXv/4FALWhXkcIeQrAG+Hsa1GQij+yCCT3KBa+lgpLQwdrCBRDKjabDZOTkygoKPAKHAcjlIGBAYyNjWHNmjV+a2B84xsGgwHj4+Po7++HQqHg4g7+9q/RaLjPJ3X2iJEVfxhabGzsrLqU8fFxTleWBXt99+JrxTByyMrK4iQzQ6Ws/TUIMiumpaXFK9MSjpSDlDEVf5A6pUwIyaeUjnh+vRKAP4smJBYFqfBBKUV/fz9GR0f9yj2KBf8i7+zsxMzMjKA0tBBSYQHZ5ORkL+HiQBWyLBXucDiwZs0aQaY1v5itoqKCsww6OzthsViQnp6O7OxspKamYnBwEBMTE1izZo3kimeMrFavXh3wb+KrFm8ymaDVatHW1ga73c6lrH1dOpZura2tRWJiohchu1yuWW5SILAZQ2NjY1i+fDlX+DcwMMDtzZ+bFgjRlqWMQpn+rwgh9XC7P70AbgtnkUVFKkzuUaFQBJR7BMQXN1FKcfToUaSkpGD16tUh3yskUMtK+Ovq6tDX18eREAvIsnUYmKpdenq6oFR4IPAtA6fTCb1ez6mcKZVKLFmyRPIBY4ODgxgdHRVNVgkJCSgpKeEa9CYmJjiXLjExkZvW2NPTw8WVGPhuktjCO0YGvpXFTHKSVRb7Vr0GWidSBPp7SF1RSyn9hhTrLApSIYRwgcVgSvTstWJIxWg0wmg0oqKiQnC5ezD3hwlnazQaLiDLSIjFCHzdHVZyX1ZWFlDVLhwolUqkp6djcHAQxcXFyMnJgVarRVNTEwB4uUnhkBilFN3d3TAajV71LeHu1TcWwmYjJSYmYnR0FFlZWbMkH0MV3vlLWfsjA18pB37VayApB6lIJZAbxZT0FxoWBak4nU40NzejqqoqZFm6GEV9Zk3Ex8eL6p8JRCpMsgCAV0CWZX/8EQqLQ1RXV4sagiYEVqsVTU1NKCoqQkFBAQC35iwTWdJqtejp6YHRaAwYQA0ElnVTKpWoq6uTtHaGEILp6WlYrVacc8453CCxvr4+zMzMIDU1FVlZWcjIyPCyInwL7wKlrBn5BIK/qldfKYfMzEzY7faokorZbJYbCqMFpVKJTZs2CX5tKNeEVadOTExg/fr1OHz4sKj9+CMVloLOycnxykRRSqFSqdDb24uCggKvDM3IyAgGBgaCxiHCxczMDFpaWrB8+XK/gWzfnh9+ADUuLg7Z2dnIa2pCTFERaF2d13tdnZ0Y2LsXCVu2oKyiQnLJw97eXq6IkV1szIpg9TusCZI/fsQ3MO0vZa3X6zlysdvtIQvvAP9SDhMTE9DpdLBarcjJyfGSchCLQKQSqGFxvrEoSAUQPmQrFKk4nU60tLRApVJxDYFMGEnoXcc3UMsCssuWLfNKQbM7ZElJCTIyMqDVatHf3+/1RVmzZo3kaUnWlMdPRweDbwDVaDRi8uhRTLz1ljsG9OUvI/nss5GcnAxnRwe0Tz6JnMREJBiNoBISCmsXsFqtWLVqld+/ByGEsyKWLl0Ki8UyKzDNLC7f/iQ2bIxl1cLR7WVSDunp6TCZTCgtLcXMzAwn5SBWRwWIrpJ+NLBoSEUogpFKoDEczPIQ08vDjjE+Po7Ozs5ZndD8gKxSqeSU0crKytDc3My5QqxPKTs7W5JhXnzrJ9zpg4mJiUg85xwoVCrgvfdg+uwzDFks6HI6kf3++0hNTkb8ueeCrloV0V75oJRy7lRNTY3g88AqjVkTol6v5/4mcXFxnBVjMBjQ09PjdV5CFd6F6k9yuVyIj49HamoqFxhnVkx3dzc3ijWUGly0lfSlxqIhlUgtla7hLtz79r2IS4rDIyse8fseoRaDQqGAzWZDb28vNBoN1q1b5xXDCRQ/sVqtaG5uRkFBATdo2+FweJW4s3hBZmamKNOXuXTT09OSNZ+5Nm2CAkDse+9i4l/PYnJ6EmWF62CqrkZbWhrUDQ0B60xEHcflwrFjx7h4T7gXklKp9JrEyFLWDQ0NMJvNKCoqgtlshlqtnhXsZe9n+wmkFcN/va/0ga+OislkwsTEBE6cOAG73R5wnrU/CYVozlmKFIuGVITCH6kMDAzgX63/gkVtgdVhxZHRIyhLK/N6j5gKWcAtQZCSkiK4QtZgMKC1tXVWjCMmJga5ubnIzc3l4gXj4+Po6elBbGwsV+QWzOrgB01XrVolbcPhpk3o/HQvenW9iI+Lx0ysDSU33og8zK4zCaSDGwwOh4Obhy2m/ygUWBPi1NQUVCoVVq9ejampKU5SMzk5mSNv3zS4byzGl1wYCYSKeTA1OFYFrdfruXnW8fHxnBXjbx2bzTanc4fE4LQmFX5f0FfO+Qo6PuuAyW7CxgLvgfdiGgSZbmtsbKyXmc5PZfIlCwC3i8TEtoP1cvDjBcuWLYPJZML4+DjXCcxSwHzZR1bfkpmZiZKSEsnvbuOffw71SQ0yU7JAQZGpTAFpbgatq/OqM2EWF7toWYd1ZmZmQAuQyT8UFxeLyr4JxcDAAMbHx7mAb1xcHEfevlXIzAUV0p/kcrlgNpvhcDi8qnuDuc/+rKiJiQkcP34cZrMZ8fHxmJyc5KQc2CynSEAI+SqAHQBWANhAKT3Me+6HAG4B4ATwXUrp24LXXYABn7A2xNTYQ6G3t5cbgsXugKH6glpaWlBcXBwypWswGNDc3Iy8vDw4HA5UVlYCCC5K3d/fD61Wi7q6uoiqWO12O7RaLcbHx7kUcGpqKvr6+lBeXi5pfQvD0EcfQbVnD/JycuBcuxqupETEfvwZAMD55S/PygoxsCFt4+PjmJiY4LqK+QpyTPBq6dKlorrKhaK3txdTU1NYuXJlyFgZS69rtVoYjUZOYiEjI8OvJcL2vnz5ciQnJ89KUYcK9vpiYGAARqMRgFvVT6lUYt++fWhsbMQbb4TVnkMAgBCyAoALwJ8A3MtIhRBSDeDvADYAKADwLwDLKaWC7qynpaXCCqcqKysFfWGF9PJoNBp0dXVh1apVsNvtGBlxt1AEK7lvb28HpRSrV6+OuJ5BpVJ5FWcNDQ3hxIkTXCcws2SkKL+nlOLkRx8h9fXXkZObC7p2LchFF0EJwKVQQfHhh1D+859wxsaCeoiVoWG0Af/q/RcuXXIpVi5d6ZWhYQpyycnJ0Ov1qKmp4YaoSwVWkGc2mwURCuA/vc6aINVqNUeI8fHxMJvNaGpqmlUz5S/YK0Qrhu05LS2N6/IeHR3F2NgYjh49ijPOOAPf/e53ce2114ZzLtoAv8HerQBepJRaAZwkhHTBTTD7hax72pGKwWDgqlmFmo/BMkaUUvT29kKr1XIB2ampKa9gnu9dian3Z2Zmht09HQzMzdiwYQPi4+MxMzPDqeMTQoI2FIaCy+VCS0sL4rOzkbN6NWhODlwXXfTF8556IUVrK6jPIHtKKX594NegoOiY6MBTlz0FwDtDo9Pp0NraitTUVK7D2t+4kHDAxpU4nU7U1taG3bXOD7YySc329naYzWbYbDZUVFTM6u4OFOxlRMPPBPp+X/jZH0II8vPzce2114JSikcffRQ6nU78yQiOQgCf834f9DwmCIuGVEJ9QdgXampqCvn5+aIuqECBWqZcRgjxErkOViHL2gmWLFnipeomFfh9NiyQxzpxy8vLZzUUZmRkIDs7G2lpaSHPISPD7Oxsdz/O8uWAn3iIa9MmuNatm/UcIQTLM5fjmOYY6nPrZ72P1c+sW7cO8fHxXuNCGhoavDqshU42ZOCnpNkAeynAJDUzMzPR2NiI8vJyzMzM4MCBA0hMTOQI0TeoKkYrxl/2h/X98Ct7/eHCCy/E6Oio12Otra0tAB6glL4W+RmYjUVDKsHAn+uzbNkyaLVaUe/3F6gNViGrVqu5IWL87Ixer0d7e3tUdEoC6cj6wrehkK+7kpyczOmu+AZPfef8APBLKBwCPHf/Gfdj2DCMwmTvG59Go0Fvb69XnQi/w3rJkiUcIbLPGaiQzRd82colS5ZIbhkajUY0NzejtraW+7syxbnx8XGu7sifpCYQWiuGjWThu0tCZQ88+im+CKWnMgSAn2or8jwmCIueVFg165IlS5CXl8eVYYuBr/vDArK+MRl2t1EqldiwYQPMZjOXnbFarZzZLTWhsO7s+Pj4oDqy/j4XX3eFBU9ZMJvFClidSGVlZcQxDrVS7ZWuB4ChoSGMjIxg9erVQV0cX+0VVsjGdGjZfvlWgcvlQnNzM9LS0lBWVhZw7XDBJxR+cx9fca68vHyWpGaw7BffihkYGIDD4UBKSopXLGZqakry1g0e/gHgBULIb+AO1C4DIFgycdGQir8LiVVOsrnIwOzZP0LAd3/4AVnfClnfgCxLqdpsNszMzCA7Oxv9/f3o6OhARkYGcnJyRNVs+IPNZuMyTkU+MQwxIIRwVb1Lly7lCLG5uRkzMzMoKCgIKNkYCXp7ezE5OSm6i5mleZmaPrMK+B3WGRkZ6OrqkrzGhWFmZgbHjh3zEp0KBF9JTdafxO9y9nXrhoaGMD4+jlWrVnl9B61WK5599lmcffbZEe2fEHIlgN8DyAawlxDSSCm9hFLaSgjZCeA4AAeA7wjN/ACLKKXscrlgt9vdC/AaAletWuV15zKZTDhx4gRWr14teO3h4WFYLBYQQqDVametGSh+wvqIEhMTUcFrrOOPs5ienkZKSgrndoi5sFh8JlppVyasVFNTw120rKo3Ozs7YEpVCPh9PNXV1ZKKGdlsNo78FQoFZ40J7bAWAjGEEgpsQqFWq4XZbObmJhkMBtTX13vt2eFw4JZbbsHq1avxwx/+MFyCj2op7qIjFafTiWPHjiE2NhaVlZWzvqxWqxXHjh3DunXrBK89MjKCnp4epKWlYcWKFYIqZFkMgi8r4A/srqXRaKDT6RAXF4ecnBy/wT0+mCSCr9kdCNPWacTHxEOlFJZBYQHfVatWebkkrAt3fHyc2y9zO4T2ErGiw5iYmKAznsOF3W5HY2MjSkpKkJ2dzXVY6/V6r36fcN0Hg8GAlpYW1NXVSTrMC3Cfm+7uboyMjEClUnHnNzU1FQkJCbj99tuxdOlS7NixI5LzFlVSWTTuD+BO7zU2Ns5qCORD7Gxkq9XKNX/V1NRwjwcjlOnpabS2tqKqqipkDIJfJQu4fXSNRoOmpiYu/ZuTk+PVNj82NsYFNYVcGP/s/ice+vQhFCYX4i+X/QWJ6sAXAqUUPT09mJmZ8euS8Ltw2X5Z3IhSGlLYiVlvkfbxBILVakVjYyOWLFnCdYT7dlhrtVq0trbC6XQGDJ4GAvvb+irNSQWNRoOpqSmcddZZUCqVXKvDT37yE7z11lsoKCjA7bffvmBlD4BFRCoWiwVHjx5FTU1N0BSbGFJhAdnCwkJYLBbu8UAFbYD7S8HkDdVxahhtxqAXsS8SExNRXl7OpX/Hx8e5orDMzEw4nU4YjUZRUwjf73sfFBQDhgEMGAZQlVnl93WsIE+hUAgWVkpMTERiYiLKysq4ylOmjM9PVysUiqj18TDwK1kDiZ2z/ZaWls4KnoZq1pyamkJbW1vUCGVsbAyDg4NeLg8b80opxeWXX47zzz8fzz33HFasWBEVl1cKLCr3x2g0Cmqy+uyzz3DmmWcGfQ3zyevq6uB0OjEwMMAN8QpUct/X1wedToeVK1fCQi24d9+90Bg1uO+M+3BG4RnhfCwONpsNLS0tMJlMnFRCTk4OMjIyQsYjWsdb8cj+R1CdVY37Nt0HpWL2BcPcRia/EKkFwc/O6PV6rgivvLwcziQn/tX7L5xdfDaWZyyP6DgMLL4kRP3PH/jNmjqdziv7xfpu2tvbsWrVKsmnDADu71tfXx9Wr17tdbNwuVy4//77AQC/+93vpIo9ye6PEBBCJOna9FV9U6lUMBgMXIGSP1FqFiNQKBSor6+HQqFAp7YTQ4YhKIgCB4YOREQqDocDra2tSEtLw+rVq0Ep5eIEnZ2dnAh0oKrTmuwa/N8V/xdwfda4V1hYGDT+Iwb87IzJZEJDQwPS0tIwNDSEe5vvxah1FFmJWfjkxk+gIJFdKCxoKjS+5A++bijLfrW1tcFiscBut6Oqqioqadzx8XH09fWhvr5+FqH89Kc/hc1mwx//+MeoKvNLiUVFKpGClaDHxMR4Vcgy0511nPKPZbPZcOzYMWRnZ6O4uJh7bnnGclxQdgH6pvqwbfm2sPfEdGSLi4uRn58PwP1ZWZyAiUCPj4+joaHBq/ZEyB2V9apEK4PE6jj4bmlGbwY0Exo4rA58/vnnyM7K5oKRYv+OLMYhddA0Pj4eJSUlSE5ORnt7OyoqKjjN3mBFgmIxPj7OjS7h3xAopXjwwQcxMTGBv/zlL6cMoQCLyP0B3Be4kM/jz/1hAb78/HyUlJR8sRlKYbPZcOTIEajVauTm5nKZGaPRiGPHjkkyGtQfQunI+oPFYsH4+DjGx8dht9u5wKmvyjzwRRYjGqLagDsGcfz48VlpV41Rg48HPsbGgo3IT8zHxMQExsfHRafXmUtS55FZkBqsbaC+vp6zUFiRoFarxcTEBCdZwGpMxICRlD9C+dWvfoWuri4899xz0QjIyilloRBDKps2beLYn40xraqqQmZm5hcb8cnwmEwmaDQaaLVaOJ1O2Gw2VFdXR+UOz77QoTRWgoEFIsfHxzEzM8MNDktPT8fk5CQ3dygaF+TExAQ6OztFxSB84xr8DmBft4Otz7/gpd5/V1cX6uvrg6bKWYf1+Pg4rFYrN3CMBaeDrd/d3Y36+novt51SiscffxyNjY144YUXJB/q5oFMKkIhlFQOHDjADbYaGxtDd3c3Vq1a5XXxBsvwDA4OYmhoCDk5OdDr9XA4HFzqN9wZOXwMDw9jaGgIdXV1YevI+oIfOB0fH4fT6cTSpUuRl5cnubD22NgY+vr6sGrVqoj2z9KpbL+s6tRisaC3t3fWBSkVWAZr9erVotZnRY1arRaTk5MBO6x1Oh06OztnrU8pxf/7f/8Pn376KXbu3BlNZTeZVITCbrcLkn08cuQIqqurMTw8DL1eP6vAK1BAlo0+tVgsqKmp4cxSJpCk0WhgNpvDLsFnNSIGgwErV66MSh1CX18ftFotlixZwl0ALNORnZ0d8V1/cHAQY2NjEYtO+YJZXf39/TAYDMjLy0Nubq6g7JcYsBhHpITFj3VptVquw1qtVqO/v3+W8DilFE8//TTeffdd7N69W7KbSQDIpCIUQkmloaEBlFLExcWhqqpKUIWsw+HgiraCdbr6luALTf2yQWMqlSoqVaZM+sFut88qi2eZDmYRhGt1sT6eaBHi0NAQRkdHsXLlSu6CZelqf82EYhEoaCoFrFYrBgYGMDAwgNjYWK6Gh3VYP/vss3jttdfw2muvRbNRkEEmFaEQQipWqxWffvopioqKsHz5FzUSQkru+RkYIeAP4dLpdEhKSuIGS/FdDl+dEqnBWv/j4uKwdOnSoETBt7r8FbD5A7PgWIwpGpmK/v5+TExMoK6uzouw+M2ETNKCWV1iNFf40gvRiGOwoDKzgJgr+uyzz+LAgQMwGAx48803o9JJ7QcyqQhFKFJhAdn4+HiUl5dzpebBCIVlMFasWBFWURUDExzSaDSYmJiAWq1GTk4OkpOT0dbWhvLy8qiINrEq1nAIi1ld4+PjmJqaQnJyMkeKfO2PaPbxAOBGi4jRkx0fH+c0V0KR4tjYGPr7+1FfXx8VQmGVuP6Cyi+99BL++te/4qKLLsK+ffvwu9/9DnUBtH0lhEwqQhFM/Hp0dJQrnx8cHOR6PoIFZFmPTV1dneRVlCaTCQMDAxgcHERiYiLy8/ORk5Mj6XFYjYuXsFKYYKlURoqxsbHIysqCVqvltEqi4bJ1d3fDYrGEZQHxh4exwClLVzPyGB0d5UrjpQ5YA+4b2fHjx/1mwV599VU8+eSTeOONN6KS0g8CmVSEwh+psOAnPyDb1dXF3XUDBWT58YFofNnYWA42vnN8fBwajYarLcnJyfEatSEWrIZGTI2LGExPT6O5uZmrZObHYaQAiwG5XC5UVVVFTFj8sRusviQ2NlZ0H5UYsFlO/ghl7969eOyxx7B3717Jxb0FQCYVofAlFdYRq1arvWQQTp48CZVKhdzc3FnWCQuYMnM+GvGBgYEBaDQavxkSh8PBxTSMRiOXSRKiIcsgVhZBLJiUJrOAbDYbF+i1WCxc6jdcASpKKRe0XrZsWVRcqr6+PgwODiIuLg4Oh0PS0bLAF4WF/poP33nnHTz88MN48803veqiIsHAwABuuOEGjI2NgRCCW2+9Fd/73veg0+nwta99Db29vSgrK8POnTuRnp4uk4pQ8FXJLRYLmpqaUFBQ4NURSynF4OAgRkZGUFJSgszMTI44mIpabm5uVLpoWUDTarWipqYmJGH5xjSYOBJ/z75g0wtXrVoVlSwCK+tftmyZ3wvC6XTOqpBl2S8hGSHWKpGYmBgVPVnAnUUaGxvjFNXYoDO+CFU4o2UZWC+Sv9aB9957Dz/72c+wd+9eSWNoIyMjGBkZwZo1a2AwGLB27Vq8+uqrePbZZ5GRkYH7778fjzzyCPR6PX75y1/KpCIUjFRCVcgyjU+WlWFq88PDw1i2bFlUKmQDqcAJBWsiZGJOiYmJnJgTM90DCStJBXaxCC3r5zc+6nS6kKlf1ikdLT1ZwH2ONBoNRyj+9sy+Gyx2JGS0LEMwQvn444/xox/9CHv37o3KxEU+tm7dijvuuAN33HEHPvjgA+Tn52NkZATnnXceTpw4IZOKUDidTgwODnJ3aiEVspRSDAwMcC4Ru1izs7Ml87NZFzB/8HokYIVVrGVApVJxn8c35SoVAvXxCIVv6pcQ4pX6dTqdnNZKJFq7wTAwMMBNgxR6jpio0/j4eMDRsvzXNjc3+z1H+/fvx/e//328/vrrknwHgqG3txfnnnsuWlpaUFJSgsnJSQDuv4GnRUMmFaFgJfe+sYpAFbKA+4vGrwA1Go0YGxuDVqvl0r7Z2dlhF1WxgGkgdyFSMHfBYrFwwtTZ2dmz1OIiQTh9PKHABKhYz4zdbkdBQUHUXJ7+/n7odDrU1dWFHSfzN1qWFbAxd9sfoRw6dAjf+9738I9//CMqdUh8zMzM4Etf+hIeeOABXHXVVUhLS+NIBQDS09Oh1+tlUhEK1uTnO93NX/2Jy+VCR0cHHA5HwHQlayAcHx/nBJRzcnIExyqiHTBl7kJKSgonzciCphqNBjabLWiXshCwPp5o9dnYbDY0NDQgPT0dNpsNBoMBaWlpnLC2FIFyMXOThYLfS6XT6WC1WlFaWori4mKvG1pDQwP+4z/+A6+++irKy8slOXYg2O12bNmyBZdccgnuvvtuAEBlZaXs/iACUvFV1A9Wcs9UzoTqpDJJAY1GA5fLFdIaGB0dRX9/P+rq6qISMBXiUrEApEajwczMjFdpuJDPzPp4Vq1aFZWUK5ObqKio4OJYvlXIoQSoQuHkyZMwGAyora2NSiaP6SKXl5dzI1AJIejs7ERCQgIefvhh7Nq1y6t6OxqglOLGG29ERkYGHn/8ce7x73//+8jMzOQCtTqdDr/61a9kUhH8Ro/2CT8gq1AovC4gs9mM5uZmlJWVhV0Q5s8ayM3N5WI4fX190Ov1UatxYRkYMTouLpeL60mampoKmpVhdTrs7h6NGA37DMHqaHyb8sQKUDEB72gSSlNTE1asWOEVuLZarfjd736HZ555BomJidiyZQt27NgRFYkJhk8++QTnnHOOlzX20EMPYePGjbj66qvR39+P0tJS7Ny5ExkZGTKpCH4jpdwkQH8VsswdkVKUyLdXhhCCuLi4qF2MUggr+Y4FiY+P98okdXZ2wm63e40jkRIszuR7MYaCPwEqf0WCrODRbDZHrReJiWz7+wwdHR244YYb8Pzzz6OiogIffvghLr300qjEisKETCpCceLECa90If+PODIygoGBAaxcuTIqwsUOhwPNzc2cic5EkXJzc0UVrgWDFMJNvmBZGRY7slqtSExMRE1NTVTcNin0ZIEvpBBYkSC/x+fkyZPckLJoXMiMUPyJbPf09OC6667D//7v/4oaWDfHkElFKA4fPoxf/epXaGtrw/nnn49t27Zh7dq1eP3111FeXo7a2tqouCOsi7mkpISrP/B1N8So3/sDi9FEKnwUCCzom5CQgNjYWGi1Wi6FKlX5PUtLS60ny4KmGo0GY2NjiImJ4TR3pf57W61WNDQ0+J0r3dfXh2uuuQZPP/001q9fL9kxb775ZrzxxhvIyclBS0sLAGDHjh146qmnOPf3oYcewubNm4UuKZOKWJjNZrz99tt48cUX8eGHH2LFihX4wQ9+gDPPPFNyl4S5I8EGh/kWrvnr9g2Gvr4+ru0/GqTIOplzc3O9akRYx69Go4HFYuEySeGUsuv1epw4cSJqIy5YtbLD4UBhYSFXvCalABULLC9fvnzW33poaAhf/epX8eSTT+KMMyIbx+KLjz76CElJSbjhhhu8SCUpKQn33ntvOEvKpBLWIpTisssuw5YtW1BaWoqXX34Zhw8fxplnnomtW7fi7LPPjrjqlNVviHFHfLt9WTzDX7HdXOiU+PbxBILT6eRqNAwGA9LT07mepFD7Ynqv0WodYM2HlFJUVlbOCswz145l7YJNUAwElvpetmzZrMDyyMgIvvKVr+C3v/0tzj33XMk+Fx+9vb3YsmWLTCphQrINTU5Oevm8drsd77//Pnbt2oVPP/0UGzZswNatW3HeeeeJrsEYGhrC8PDwrGHtYsDiGf6K7WJiYgQLK4ULfh/PGB3Dvt59uKj8ooATDBn47sbk5GRQy4uJH0WrzoVSyk1VDKXnwtdaYQJUQpo1GfFWVFTMKmAcGxvD9u3b8eijj+L888+X7HP5wh+pPPvss0hJScG6devw61//Wky3s0wq0YDD4cDHH3+MXbt24cMPP8SqVauwbds2XHDBBUHvpkzjw2g0ora2VlJ3ihXb8TuUKysroxowra6uRkpKCr7xj2/A5DAhSZWE5654TvA6/iwvZg2wkaLREj+ilHICUWK7mYUIUAHuG1FDQwOWLFkyqydMq9XiqquuwoMPPohLLrlEss/lD76kMjY2hqysLBBC8OMf/xgjIyN45plnhC4nk0q04XQ68dlnn2H37t3Yt28fVqxYgW3btuHiiy/2qi2Ito4s8IWwEpOtFFpsJwb++nh++P4P0aptRV1OHX7xpV+EvTarKxkaGoLdbkd5eTny8vIkJ0Ymj6BWqyO25Pw1ETILprW1FeXl5bPqgfR6Pa666ir8+Mc/xpYtWyL9OCHhSypCnwsAmVTmEi6XC4cOHcKuXbvwzjvvoKKiAlu3bsW6deuwe/duXH311VHr3wgkrBSs2E7sxRSoj8dkN6FnsgcVaRWIV0UWSGV6ssuXL+cyYE6nk7NgwmlI5INSyrmG4XR8h4LRaMTo6Cj6+voQFxeHgoICLg4DuEl5+/bt+P73v48rr7xS0mMHgi9xjIyMcDeexx57DAcOHMCLL74odDmZVOYLLpcLTU1NeOqpp/Diiy9i06ZNuOqqq7B58+aI9Gr9gVkPoeo3fMeBZGZmIicnR1BGJtp9PEDgsni73c4VrondNx9MxDshIQEVFRXR+AhwOBxoaGhAaWkp0tLSuH13dnbivffeQ1tbG+6++25cc801UTm+L6699lp88MEH0Gq1yM3Nxc9+9jN88MEHaGxsBCEEZWVl+NOf/iRGlF0mlfmEw+HA+eefj0cffRTx8fHYtWsXp9i1detWbNmyJeLuYyasJFYLlwkiaTQaLiMTqNgu2n08lFJ0dXVxRWfBMkK++05LS0NOTg43riIQWEd2cnJy1JrzHA4HGhsbUVxcPCsbNjY2hltvvRVWqxWTk5P47ne/i29961tR2UeUIZPKfMPhcHhdiJRSnDhxArt27cIbb7yBpKQkXHHFFbj88suRk5Mj6s47NDSEkZGRiIWVAhXbpaeno7+/H9PT05IHlhnY+QAwK6UrZN+shkev13PDz7Oysrz26nK5uCbQaAk4OZ1ONDQ0oKioaJaIktlsxtVXX42vf/3r+OY3vwmn04nJycmoyFnMAWRSWchgfSa7d+/Gq6++CrVajcsvvxxbt25Ffn5+wAuMUuo1ekLKi50V242NjWF0dJSrMM3OzpacVKQOmE5PT3MNhHFxcZx8Znt7O9LT01FaWirh7r+A0+lEY2MjCgoKZrkRFosF1157La666irceuutC6mHJ1zIpHKqgKnI7d69G3v27IHT6cTll1+Obdu2obi42Ettrr29HQAkUYr3B36mKi8vb1axXbhSAr7HaGlpQVJSkmAJCTFgPUm9vb1Qq9UoLi4W3KEsBkx1Li8vDwUFBV7PWa1WfOMb38All1yCO+64Q9LP6K/8PoBQtWTH9EAmlVMRlFKMjIzglVdewSuvvAKTyYQtW7bgoosuwvPPP49vf/vbUVM5C6T1GqzYTmzg1ul0orm5GRkZGVG1Hpqbm7n2ABYwdTgcYY9m9XcM1qLgq0tjt9tx44034pxzzsHdd98t+d/KX/n9fffd50+oWtLjQiaVxQGNRoO//e1vePjhh1FZWYkLLrgAW7duFR2DCAU2QjUvLy+kFmq4ynaBeoWkRDDNWt8MGKuMFTsShGX3srOzZx3D4XDg5ptvxtq1a3H//fdHzeXxTRUHUGqT+rAyqSwW3HTTTfjqV7+KTZs24bXXXsMrr7yCkZERXHzxxbjyyisj7u8R2sfjD0KV7ex2OxobG1FUVCRqrrQYsPiGEGJklbEajQbT09OCu8FdLheam5uRmZk5axyL0+nEbbfdhuXLl+OnP/1pVGMovqTC15TlCVVLfViZVBYLXC7XrC/65OQkXn/9dbzyyis4efIkLrroImzbto2bXCgUQpTUhCJQsZ1KpUJTUxPKysqiMvcZ+MIKys/PnxXfCAVfKUo25tRXAoFlktLT02cVMjqdTtx5550oKCjAgw8+GPWgbDBSATihaqkPK5PK6QKDwYA333wTu3btwokTJzhNmHXr1gUlGLHzeMSAuRqjo6PQ6XTIzs5GaWmpZJP8+GA1IoWFhRFbQfwxpyx+xAimo6MDqamps2JBLpcLd911F1JSUvA///M/UekK94Xs/swNFtyG5gNmsxlvvfUWdu3ahaamJnzpS1/Ctm3bsGnTJq+08OTkJNrb2yVVg/O3l6amJixduhQul0tQsZ1YsCrW4uLiqAzaMplMXEVxTEwMiouLkZOTw2WSXC4XfvCDH0ChUOC3v/3tnBAKMJtUAghVS31YmVQC4eWXX8aOHTvQ1taGgwcPYt26dQDcf6gVK1agsrISALBp0yb88Y9/jM5u5wBWqxXvvvsuXn75ZRw5cgRnnnkmtm3bBq1WC6vViu3bt0elkxkIrCcrpbIdi9OUlJSELUYeCqxfKDExEQUFBZx7ZzKZ8Nprr8FsNkOlUuHJJ5+cM0LxV36/bds2f0LVUh9aJpVAaGtrg0KhwG233YZHH33Ui1REdm2eMrDZbHj//ffxy1/+EsePH8fFF1+M7du340tf+pLk/TxM1S7UVMJIlO2YtEA04zSMUOLj42f1CxmNRvznf/4nDh06hISEBHzta1/DD3/4w6jsYwEhqqQifRPIHGLFihXzvYU5h1qtRn5+PmJiYtDW1oaGhgbs2rULDzzwAOrr67Ft2zacf/75EVsuU1NTaGtrE6QnSwhBeno60tPTvfRVenp6ghbbsWyVP2kBqcAqfllHs+9zv//970EIQVtbGxwOB7q6uqKyj9MJp7SlwnDeeefNslRqamqwfPlypKSk4Be/+AXOOeccyTc6n/DtR3I6nfj000+xe/duvPfee6iursa2bdtw0UUXidZgkUpPNlixHeCe3scfJCY1mIiTSqWa1UJAKcVjjz2GY8eO4fnnn49Kk+UCxunt/lx44YUYHR2d9aIHH3wQW7duBTCbVKxWK2ZmZpCZmYkjR45g27ZtaG1tRUpKyhxsf/7BNGFefvllvPPOO1i2bBknOhVqLIZWq0V3dzfq6+slV+1nxXZjY2MwGo3Iz89HeXl51HRr29vboVQqZ6nCUUrxxBNPYP/+/di5c2dUVOkYysrKkJycDKVSiZiYGBw+fDhqxxKB09v9+de//iX6PbGxsdwFsXbtWlRUVKCjo4MjncUOhUKBjRs3YuPGjXC5XGhsbMTLL7+MX//61ygpKcHWrVuxefPmWeln1mezevXqqOitJCQkID8/H2NjY1ixYgUcDgdaW1slV7ZjXdMKhcIvoTz11FP46KOPsHv37qgSCsP7778fNWtsIWJuwtxzjPHxcTidTgDu4U6dnZ1YsmRJwNe//PLLqKmpgUKhmHUnefjhh7F06VJUVlbi7bffjuq+owGFQoE1a9bg4YcfRkNDAx588EH09fXh8ssvx/bt2/Hcc89hYmICL730Ejo7O6NGKIC7apcp0ufn56O4uBhr167lZB9OnDiBAwcOoLu7GzMzMwjHimbK+gBmSX5SSvHss89yqfpozE+ScQq4P8GwZ88e3HnnnRgfH0daWhrq6+vx9ttvY/fu3fjJT34ClUoFhUKBn/3sZ7j88ssDrhMoi3T8+HFce+21OHjwIIaHh3HhhReio6MjKpokcw3mHuzatQvPPvssFAoFbr/9dmzfvh3Z2dmSF7axqX7+hnDxEYmyHROKcjgcfru///a3v2Hnzp34xz/+EdW5xnyUl5cjPT0dhBDcdtttuPXWW+fkuCFwers/wXDllVf61Qjdvn07tm/fLnidQFmk1157Dddccw1iY2NRXl6OpUuX4uDBg5IPi5oPEEKwYsUKLFu2DCtXrsSDDz6IN954A9dddx3UajWuuOIKbN26FXl5eRETDCue8zcm1BcqlQr5+fnIz8/nFOIGBgZCFtuxKQdsBrTv8zt37sQLL7yAvXv3zhmhAO7B6YWFhdBoNLjoootQVVUVtdlACwWnNKlEG0NDQ9i0aRP3e1FREYaGhuZxR9Jj8+bN2L59O1QqFWpqanDfffehv78fu3fvxk033QRKKacJU1RUJJpgGKGIHcYOAEqlEjk5OcjJyeGK7UZGRtDe3j6r2K6npyfg/OQ9e/bgmWeewd69e6NWdRwIrCEyJycHV155JQ4ePCiTymKBkCzS6QjfjBghBKWlpbj77rtx1113YWRkBLt378btt98Oi8WCLVu2YOvWrYJEmUwmE5qbm8MiFF8oFApkZWUhKyvLq9ius7MTgNvCqa+vn7WnN954A0888QT27t0b0UD4cGA0GuFyuZCcnAyj0Yh33nkHP/nJT+Z0D/OB04ZUwskiFRYWYmBggPt9cHAwZCv+YgIhBAUFBbjzzjtxxx13QKPRYM+ePbj77ruh1+uxefNmbNu2ze8MJKPRiObmZtTU1EieyucX2/X09HBTEg8fPoz4+HikpaUhKSkJhw8fxm9+8xvs3bs3GuppITE2Nsa55w6HA9dddx0uvfTSOd/HXOOUDtRKDd96l9bWVlx33XVcoPaCCy5AZ2enoEDtjh078NRTT3GFXg899BA2b94c1f3PJSYmJvDqq6/ilVdewejoKC655BJceeWVWLFiBXp6ejA2Noa6urqoWge9vb2coLdCoeCK7Q4dOoS77roLk5OT+NGPfoSvf/3rp1VKVwCiGqhdlCllsdizZw+Kioqwf/9+XHbZZdwIy5qaGlx99dWorq7GpZdeiieeeEJU5ueuu+5CY2MjGhsbFxWhAEBmZiZuueUW7N27F/v27UNVVRUefPBBrF+/Hlu2bMHU1FRU4xd9fX2Ymprymi9ECEFSUhKUSiWSk5Px6quvwm634y9/+UvU9iFjNmRLJUrYsWMHkpKScO+99873VuYMra2tuPbaa3HjjTfi888/x4kTJzjZzFCaMGLQ398PnU6Hurq6WWt+9tlnuO+++/D666+fVq6qSMiWyqmKP/zhD6irq8PNN98cDfWuBYfk5GS8/PLLuOeee/Dyyy/j888/x9lnn40///nPOOOMM3Dffffh008/5QoTw8HAwEBAQjl06BDuvfdevPbaa1EllLfeeguVlZVYunQpHnnkkagd51SFbKlEgGAZpU2bNiErKwuEEPz4xz/GyMgInnnmmXnY5cKAxWLhNGGOHj2Ks846C9u2bcNZZ50luJlvcHAQ4+PjfqU2Gxoa8J3vfAd79uyJ2vRCwN24uXz5crz77rsoKirC+vXr8fe//x3V1dVRO2YUcHo3FC4GLGZ9l3Bgs9nw3nvvYdeuXdi/fz82btyIbdu24dxzzw3YIjA0NMSNbfWNax07dgzf/va3sXv3bixbtiyqe9+/fz927NjBtWw8/PDDAHCqabDI7s+piJGREe7nPXv2oLa2VtT7F7OJrVarcemll+Lpp59GU1MTrr/+evzzn//E2Wefjdtuuw3//Oc/YbFYuNcPDw9jdHTUL6EcP34c3/72t7Fz586oEwrgJje++v5iLIiMFKdNncpc47777kNjYyMIISgrK8Of/vQnwe91Op34zne+42ViX3HFFaeaiS0IMTExuOCCC3DBBRdwmjC7du3CT3/6U9TW1iI3NxcWiwWPPvroLEI5ceIEbr75Zrzwwguoqqqap08gwxcyqUQJ//d//xf2ew8ePIilS5dyndXXXHMNXnvttUVJKnwolUqce+65OPfcc+FyufDQQw/h6aefRnp6Om666SZs27YNl1xyCZKSktDd3Y0bb7wRzz33nGgrMBKc7gWRQiCTygKEPxP7wIED87ijuYfL5UJ/fz+OHTuGxMRENDQ0cJow2dnZ6OnpwUsvvYT6+vo53df69evR2dmJkydPorCwEC+++CJeeOGFOd3DQodMKjIWJGJiYvDnP/+Z+33t2rVYu3YtHnroIXz88ccYHBycF9GtmJgY/OEPf8All1wCp9OJm2++GTU1NXO+j4UMmVQWIGQTOzAUCgW+9KUvzeseNm/evOgqpKWEnP1ZgOCb2DabDS+++CKuuOKK+d6WDBmCIFsqCxBSm9gLVHxZxiKFXPx2GqCsrAyHDx+WO3VlMMjFbzJkzCV27NiBwsJC1NfXo76+Hm+++eZ8b+mUguz+nAYghODiiy9eaOLLCxp33XXXadVhLiVkUjkNcDqKL8uYP8juz2kAf+LLMoLjdJOtkBIyqSxyGI1GGAwG7ud33nlHdFn7zTffjJycHK/36XQ6XHTRRVi2bBkuuuiiU+7Cu/DCC1FbWzvr32uvvYZ///d/R3d3NxobG5Gfn4977rlnvrd7SkHO/ixy9PT0zBJffuCBB0St8dFHHyEpKQk33HADJ99w3333ISMjA/fffz8eeeQR6PV6/PKXv5R8//ONRSpbIeupyJh/+F5clZWV+OCDD5Cfn4+RkRGcd955OHHixDzvUhqMjIwgPz8fAPDYY4/hwIEDePHFF+d5V5JCnlAoY+FhbGyMu/Dy8vIwNjY2zzuSDpHIVsiQSUWGBCCESD57eT4RiWyFjIXp/shYgCCElAF4g1Ja6/n9BIDzKKUjhJB8AB9QSivnc48yFgbk7I+McPEPADd6fr4RwGvzuBcZCwgyqcgICULI3wHsB1BJCBkkhNwC4BEAFxFCOgFc6PldyFrPEEI0hJAW3mM7CCFDhJBGzz9ZV+AUhuz+yJhTEELOBTAD4DmeK7UDwAyl9NH53JsMaSBbKjLmFJTSjwDo5nsfMqIHmVRkLBTcQQhp9rhH6fO9GRnhQyYVGQsBTwKoAFAPYATAr+d1NzIigkwqMuYdlNIxSqmTUuoC8BSADfO9JxnhQyYVGfMOT50Lw5UAFlWjzekGuaJWxpzCk54+D0AWIWQQwE8BnEcIqYe776sXwG3ztT8ZkUNOKcuQIUNSyO6PDBkyJIVMKjJkyJAUMqnIkCFDUsikIkOGDEkhk4oMGTIkhUwqMmTIkBQyqciQIUNS/H+chCSsfiQV/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prev_indices = list(y_train.index)\n",
    "X_train[1], y_train = remove_outliers(X_train[1], y_train)\n",
    "\n",
    "removed_indices = []\n",
    "j = 0\n",
    "for i in prev_indices:\n",
    "    if i not in list(y_train.index):\n",
    "        removed_indices.append(j)\n",
    "        \n",
    "    j = j + 1\n",
    "\n",
    "X_train[0] = np.delete(X_train[0], removed_indices, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a4def",
   "metadata": {},
   "source": [
    "Apply random cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31a4033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0] = tf.image.random_crop(X_train[0], (X_train[0].shape[0], X_train[0].shape[1], 256, 256))\n",
    "X_test[0] = tf.image.random_crop(X_test[0], (X_test[0].shape[0], X_test[0].shape[1], 256, 256))\n",
    "X_val[0] = tf.image.random_crop(X_val[0], (X_val[0].shape[0], X_val[0].shape[1], 256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2de1d4",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "779f66c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grey_to_rgb(img_array):\n",
    "    width = img_array.shape[-3]\n",
    "    height = img_array.shape[-2]\n",
    "    new_img_array = np.empty((img_array.shape[0], img_array.shape[1], width, height, 3), dtype=np.uint8)\n",
    "    i = 0\n",
    "    for p in img_array:\n",
    "        new_p = np.empty((p.shape[0], width, height, 3), dtype=np.float16)\n",
    "        j = 0\n",
    "        for s in p:\n",
    "            s = np.squeeze(s)\n",
    "            out = np.empty((width, height, 3), dtype=np.float16)\n",
    "            out[:, :, 0] = s\n",
    "            out[:, :, 1] = s\n",
    "            out[:, :, 2] = s\n",
    "\n",
    "            new_p[j] = out\n",
    "\n",
    "            j = j + 1\n",
    "\n",
    "        new_img_array[i] = new_p\n",
    "\n",
    "        i = i + 1\n",
    "    \n",
    "    return new_img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9967cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class image_clinical(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.relu = nn.ReLU()\n",
    "        self.clinical_track()\n",
    "        self.image_track()\n",
    "        \n",
    "        self.fc1_cat = nn.Linear(415, 26)\n",
    "        self.fc2_cat = nn.Linear(26, num_classes)\n",
    "        \n",
    "    def clinical_track(self):\n",
    "        self.fc1 = nn.Linear(603, 50)\n",
    "        self.fc2 = nn.Linear(50, 25)\n",
    "        self.fc3 = nn.Linear(25, 15)\n",
    "\n",
    "    def image_track(self):\n",
    "        self.res = None\n",
    "    \n",
    "    def forward(self, data):\n",
    "        image_data = data[0]\n",
    "        clinical_data = data[1]\n",
    "        \n",
    "        # clinical\n",
    "        clinical_x = self.relu(self.fc1(clinical_data))\n",
    "        clinical_x = self.relu(self.fc2(clinical_x))\n",
    "        clinical_x = self.relu(self.fc3(clinical_x))\n",
    "        \n",
    "        # image\n",
    "        image_x = self.res(image_data)\n",
    "        \n",
    "        x = torch.cat([clinical_x, image_x], dim=1)\n",
    "        \n",
    "        x = self.relu(self.fc1_cat(x))\n",
    "        x = self.fc2_cat(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def train_func(self, config, data):\n",
    "        id_X_train = data[0]\n",
    "        id_y_train = data[1]\n",
    "        self.res = data[2]\n",
    "        X_train = ray.get(id_X_train)\n",
    "        y_train = ray.get(id_y_train)\n",
    "        epochs = config['epochs']\n",
    "        batch_size = config['batch_size']\n",
    "        lr = config['lr']\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        for epoch in range(int(epochs)):\n",
    "            running_loss = 0.0\n",
    "            for i in range((X_train[1].shape[0]-1)//batch_size + 1):\n",
    "\n",
    "                start_i = i*batch_size\n",
    "                end_i = start_i+batch_size\n",
    "\n",
    "                xb = [X_train[0][start_i:end_i], X_train[1][start_i:end_i]]\n",
    "\n",
    "                yb = y_train[start_i:end_i]\n",
    "                print(type(yb))\n",
    "                yb = Variable(yb)\n",
    "\n",
    "                xb[0] = torch.unsqueeze(xb[0].type(torch.float), -1)\n",
    "                xb[0] = grey_to_rgb(xb[0])/255\n",
    "                # reshape to have 3 channels\n",
    "                xb[0] = np.reshape(xb[0], (xb[0].shape[0], xb[0].shape[-1], xb[0].shape[1], xb[0].shape[2], xb[0].shape[3]))\n",
    "                xb[0] = torch.from_numpy(xb[0]).type(torch.float)\n",
    "                xb[1] = xb[1].type(torch.float)\n",
    "                pred = self(xb)\n",
    "\n",
    "                optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "                loss = self.criterion(pred, yb)\n",
    "        \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # print stats\n",
    "                running_loss += loss.item()\n",
    "                pred = pred.detach()\n",
    "                self.loss = running_loss\n",
    "                pred = np.argmax(pred, axis=1)\n",
    "                self.accuracy = accuracy_score(yb, pred)\n",
    "                self.f1_score = f1_m(yb, pred)\n",
    "                self.recall = recall_m(yb, pred)\n",
    "                self.balanced_acc = balanced_accuracy_score(yb, pred)\n",
    "                if i % 2000 == 1999: # print every 2000 mini-batches\n",
    "                    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}', 'Accuracy: %.4f' %self.accuracy, 'F1: %.4f' %self.f1_score, 'Recall: %.4f' %self.recall, 'Balanced Accuracy: %.4f' %self.balanced_acc)\n",
    "                tune.report(loss=running_loss, accuracy=self.accuracy)\n",
    "                running_loss = 0.0\n",
    "\n",
    "        print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e05c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from ray.tune.schedulers.async_hyperband import ASHAScheduler\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "class image_model:\n",
    "\n",
    "    def __init__(self, load_model=True):\n",
    "        self.load_model = load_model\n",
    "        self.res = models.video.r3d_18(pretrained=False)\n",
    "\n",
    "    def main(self, X_train, y_train, num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
    "        # get number of classes in y\n",
    "        y = []\n",
    "        for i in y_train:\n",
    "            i = int(i)\n",
    "            y.append(i)\n",
    "        \n",
    "        y = list(set(y))\n",
    "        num_classes = len(y)\n",
    "\n",
    "        # make classes start from 0\n",
    "        class_dict = dict()\n",
    "        for i in range(num_classes):\n",
    "            class_dict[y[i]] = i\n",
    "\n",
    "        i = 0\n",
    "        for val in y_train:\n",
    "            new_val = class_dict[int(val)]\n",
    "            y_train[i] = new_val\n",
    "            i = i + 1\n",
    "\n",
    "        if len(y_train.shape) > 1:\n",
    "            self.multi_target = True\n",
    "        else:\n",
    "            self.multi_target = False\n",
    "            \n",
    "        id_X_train = ray.put(X_train)\n",
    "        id_y_train = ray.put(y_train)\n",
    "\n",
    "        self.model = image_clinical(num_classes)\n",
    "\n",
    "        config = {\n",
    "            'epochs':tune.choice([50, 100, 150]),\n",
    "            'batch_size':tune.choice([8, 16, 20]),\n",
    "            'lr':tune.loguniform(1e-4, 1e-1)\n",
    "        }      \n",
    "        scheduler = ASHAScheduler(\n",
    "            max_t=max_num_epochs,\n",
    "            grace_period=1,\n",
    "            reduction_factor=3)\n",
    "        if torch.cuda.is_available():\n",
    "            result = tune.run(\n",
    "                tune.with_parameters(self.model.train_func, data=[id_X_train, id_y_train, self.res]),\n",
    "                resources_per_trial={\"cpu\":4, \"gpu\":gpus_per_trial},\n",
    "                config=config,\n",
    "                metric=\"accuracy\",\n",
    "                mode=\"min\",\n",
    "                num_samples=num_samples,\n",
    "                scheduler=scheduler\n",
    "            )\n",
    "        else:\n",
    "            result = tune.run(\n",
    "                tune.with_parameters(self.model.train_func, data=[id_X_train, id_y_train, self.res]),\n",
    "                resources_per_trial={\"cpu\":4},\n",
    "                config=config,\n",
    "                metric=\"accuracy\",\n",
    "                mode=\"min\",\n",
    "                num_samples=num_samples,\n",
    "                scheduler=scheduler\n",
    "            )\n",
    "\n",
    "        best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "        print(\"Best trial config: {}\".format(best_trial.config))\n",
    "        print(\"Best trial final validation loss: {}\".format(\n",
    "            best_trial.last_result[\"loss\"]))\n",
    "        print(\"Best trial final validation accuracy: {}\".format(\n",
    "            best_trial.last_result['accuracy']))\n",
    "\n",
    "        self.model.train_func(config=best_trial.config, data=[id_X_train, id_y_train, self.res])\n",
    "\n",
    "        torch.save(self.model.state_dict(), \"torch_image_clinical_model.pth\")\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def test_model(self, X_test, y_test):\n",
    "        X_test = [torch.from_numpy(np.array(X_test[0])).type(torch.float), torch.from_numpy(np.array(X_test[1])).type(torch.float)]\n",
    "        X_test[0] = torch.unsqueeze(X_test[0], -1)\n",
    "        X_test[0] = grey_to_rgb(X_test[0])/255\n",
    "        # reshape to have 3 channels\n",
    "        X_test[0] = np.reshape(X_test[0], (X_test[0].shape[0], X_test[0].shape[-1], X_test[0].shape[1], X_test[0].shape[2], X_test[0].shape[3]))\n",
    "        i = 0\n",
    "        for arr in X_test:\n",
    "            if type(arr) == np.ndarray:\n",
    "                arr = torch.from_numpy(arr).type(torch.float)\n",
    "                X_test[i] = arr\n",
    "            i = i + 1\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        y_test = torch.from_numpy(np.array(y_test)).type(torch.float)\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.model(X_test)\n",
    "            confusion_matrix(y_test, y_pred, save_name=\"image_only_c_mat_torch\")\n",
    "            test_loss = self.criterion(y_pred, y_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            f1_score = f1_m(y_test, y_pred)\n",
    "            recall = recall_m(y_test, y_pred)\n",
    "            balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "        return test_loss, accuracy, f1_score, recall, balanced_acc\n",
    "\n",
    "    def get_model(self, X_train=None, y_train=None, X_val=None, y_val=None, epochs=10, batch_size=128):\n",
    "        \n",
    "        if self.load_model:\n",
    "            self.model = image_clinical()\n",
    "            self.model.res = self.res\n",
    "            self.model.load_state_dict(torch.load(\"torch_image_clinical_model.pth\"), strict=False)\n",
    "        else:\n",
    "            self.model = self.main(X_train, y_train)\n",
    "\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a03fc7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = image_model(load_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "366e7877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "i = 0\n",
    "for train, val in zip(X_train, X_val):\n",
    "    train = torch.from_numpy(np.array(train))\n",
    "    val = torch.from_numpy(np.array(val))\n",
    "    \n",
    "    X_train[i] = train\n",
    "    X_val[i] = val\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "y_train = torch.from_numpy(np.array(y_train))\n",
    "y_val = torch.from_numpy(np.array(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43355854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 100, 256, 256])\n",
      "torch.Size([6, 603])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 12:46:15,197\tWARNING function_runner.py:598 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "2022-07-09 12:46:15,581\tINFO trial_runner.py:803 -- starting train_func_0787e_00000\n",
      "2022-07-09 12:46:15,693\tERROR syncer.py:119 -- Log sync requires rsync to be installed.\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.0.0)/charset_normalizer (2.0.6) doesn't match a supported version!\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m   warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.0.0)/charset_normalizer (2.0.6) doesn't match a supported version!\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m   warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-09 12:46:19 (running for 00:00:04.55)<br>Memory usage on this node: 11.4/15.6 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 9.000: None | Iter 3.000: None | Iter 1.000: None<br>Resources requested: 4.0/8 CPUs, 0/0 GPUs, 0.0/2.79 GiB heap, 0.0/1.4 GiB objects<br>Result logdir: C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15<br>Number of trials: 10/10 (9 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00000</td><td>RUNNING </td><td>127.0.0.1:14900</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00755458 </td></tr>\n",
       "<tr><td>train_func_0787e_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000117863</td></tr>\n",
       "<tr><td>train_func_0787e_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000438003</td></tr>\n",
       "<tr><td>train_func_0787e_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0303044  </td></tr>\n",
       "<tr><td>train_func_0787e_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000203301</td></tr>\n",
       "<tr><td>train_func_0787e_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00173267 </td></tr>\n",
       "<tr><td>train_func_0787e_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000246187</td></tr>\n",
       "<tr><td>train_func_0787e_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0772869  </td></tr>\n",
       "<tr><td>train_func_0787e_00008</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000393541</td></tr>\n",
       "<tr><td>train_func_0787e_00009</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.00309822 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 12:46:19,860\tINFO trial_runner.py:803 -- starting train_func_0787e_00001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_func pid=14900)\u001b[0m <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=)\u001b[0m C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.0.0)/charset_normalizer (2.0.6) doesn't match a supported version!\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m   warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.0.0)/charset_normalizer (2.0.6) doesn't match a supported version!\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m   warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-09 12:46:24 (running for 00:00:09.63)<br>Memory usage on this node: 13.1/15.6 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 9.000: None | Iter 3.000: None | Iter 1.000: None<br>Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.79 GiB heap, 0.0/1.4 GiB objects<br>Result logdir: C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15<br>Number of trials: 10/10 (8 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00000</td><td>RUNNING </td><td>127.0.0.1:14900</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00755458 </td></tr>\n",
       "<tr><td>train_func_0787e_00001</td><td>RUNNING </td><td>127.0.0.1:22024</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000117863</td></tr>\n",
       "<tr><td>train_func_0787e_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000438003</td></tr>\n",
       "<tr><td>train_func_0787e_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0303044  </td></tr>\n",
       "<tr><td>train_func_0787e_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000203301</td></tr>\n",
       "<tr><td>train_func_0787e_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00173267 </td></tr>\n",
       "<tr><td>train_func_0787e_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000246187</td></tr>\n",
       "<tr><td>train_func_0787e_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0772869  </td></tr>\n",
       "<tr><td>train_func_0787e_00008</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000393541</td></tr>\n",
       "<tr><td>train_func_0787e_00009</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.00309822 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-09 12:46:30 (running for 00:00:14.71)<br>Memory usage on this node: 13.8/15.6 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 9.000: None | Iter 3.000: None | Iter 1.000: None<br>Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.79 GiB heap, 0.0/1.4 GiB objects<br>Result logdir: C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15<br>Number of trials: 10/10 (8 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00000</td><td>RUNNING </td><td>127.0.0.1:14900</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00755458 </td></tr>\n",
       "<tr><td>train_func_0787e_00001</td><td>RUNNING </td><td>127.0.0.1:22024</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000117863</td></tr>\n",
       "<tr><td>train_func_0787e_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000438003</td></tr>\n",
       "<tr><td>train_func_0787e_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0303044  </td></tr>\n",
       "<tr><td>train_func_0787e_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000203301</td></tr>\n",
       "<tr><td>train_func_0787e_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00173267 </td></tr>\n",
       "<tr><td>train_func_0787e_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000246187</td></tr>\n",
       "<tr><td>train_func_0787e_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0772869  </td></tr>\n",
       "<tr><td>train_func_0787e_00008</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000393541</td></tr>\n",
       "<tr><td>train_func_0787e_00009</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.00309822 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-09 12:46:35 (running for 00:00:19.77)<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 9.000: None | Iter 3.000: None | Iter 1.000: None<br>Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.79 GiB heap, 0.0/1.4 GiB objects<br>Result logdir: C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15<br>Number of trials: 10/10 (8 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00000</td><td>RUNNING </td><td>127.0.0.1:14900</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00755458 </td></tr>\n",
       "<tr><td>train_func_0787e_00001</td><td>RUNNING </td><td>127.0.0.1:22024</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000117863</td></tr>\n",
       "<tr><td>train_func_0787e_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000438003</td></tr>\n",
       "<tr><td>train_func_0787e_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0303044  </td></tr>\n",
       "<tr><td>train_func_0787e_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000203301</td></tr>\n",
       "<tr><td>train_func_0787e_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00173267 </td></tr>\n",
       "<tr><td>train_func_0787e_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000246187</td></tr>\n",
       "<tr><td>train_func_0787e_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0772869  </td></tr>\n",
       "<tr><td>train_func_0787e_00008</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000393541</td></tr>\n",
       "<tr><td>train_func_0787e_00009</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.00309822 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-09 12:46:40 (running for 00:00:24.83)<br>Memory usage on this node: 15.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 9.000: None | Iter 3.000: None | Iter 1.000: None<br>Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.79 GiB heap, 0.0/1.4 GiB objects<br>Result logdir: C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15<br>Number of trials: 10/10 (8 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00000</td><td>RUNNING </td><td>127.0.0.1:14900</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00755458 </td></tr>\n",
       "<tr><td>train_func_0787e_00001</td><td>RUNNING </td><td>127.0.0.1:22024</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000117863</td></tr>\n",
       "<tr><td>train_func_0787e_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000438003</td></tr>\n",
       "<tr><td>train_func_0787e_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0303044  </td></tr>\n",
       "<tr><td>train_func_0787e_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000203301</td></tr>\n",
       "<tr><td>train_func_0787e_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00173267 </td></tr>\n",
       "<tr><td>train_func_0787e_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000246187</td></tr>\n",
       "<tr><td>train_func_0787e_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0772869  </td></tr>\n",
       "<tr><td>train_func_0787e_00008</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000393541</td></tr>\n",
       "<tr><td>train_func_0787e_00009</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.00309822 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-09 12:46:45 (running for 00:00:29.90)<br>Memory usage on this node: 15.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 9.000: None | Iter 3.000: None | Iter 1.000: None<br>Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.79 GiB heap, 0.0/1.4 GiB objects<br>Result logdir: C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15<br>Number of trials: 10/10 (8 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00000</td><td>RUNNING </td><td>127.0.0.1:14900</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00755458 </td></tr>\n",
       "<tr><td>train_func_0787e_00001</td><td>RUNNING </td><td>127.0.0.1:22024</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000117863</td></tr>\n",
       "<tr><td>train_func_0787e_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000438003</td></tr>\n",
       "<tr><td>train_func_0787e_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0303044  </td></tr>\n",
       "<tr><td>train_func_0787e_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000203301</td></tr>\n",
       "<tr><td>train_func_0787e_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00173267 </td></tr>\n",
       "<tr><td>train_func_0787e_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000246187</td></tr>\n",
       "<tr><td>train_func_0787e_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0772869  </td></tr>\n",
       "<tr><td>train_func_0787e_00008</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000393541</td></tr>\n",
       "<tr><td>train_func_0787e_00009</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.00309822 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-09 12:46:50 (running for 00:00:35.00)<br>Memory usage on this node: 13.8/15.6 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 9.000: None | Iter 3.000: None | Iter 1.000: None<br>Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.79 GiB heap, 0.0/1.4 GiB objects<br>Result logdir: C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15<br>Number of trials: 10/10 (8 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00000</td><td>RUNNING </td><td>127.0.0.1:14900</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00755458 </td></tr>\n",
       "<tr><td>train_func_0787e_00001</td><td>RUNNING </td><td>127.0.0.1:22024</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000117863</td></tr>\n",
       "<tr><td>train_func_0787e_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000438003</td></tr>\n",
       "<tr><td>train_func_0787e_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0303044  </td></tr>\n",
       "<tr><td>train_func_0787e_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000203301</td></tr>\n",
       "<tr><td>train_func_0787e_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00173267 </td></tr>\n",
       "<tr><td>train_func_0787e_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000246187</td></tr>\n",
       "<tr><td>train_func_0787e_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0772869  </td></tr>\n",
       "<tr><td>train_func_0787e_00008</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000393541</td></tr>\n",
       "<tr><td>train_func_0787e_00009</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.00309822 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-09 12:46:55 (running for 00:00:40.05)<br>Memory usage on this node: 15.1/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 9.000: None | Iter 3.000: None | Iter 1.000: None<br>Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.79 GiB heap, 0.0/1.4 GiB objects<br>Result logdir: C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15<br>Number of trials: 10/10 (8 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00000</td><td>RUNNING </td><td>127.0.0.1:14900</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00755458 </td></tr>\n",
       "<tr><td>train_func_0787e_00001</td><td>RUNNING </td><td>127.0.0.1:22024</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000117863</td></tr>\n",
       "<tr><td>train_func_0787e_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000438003</td></tr>\n",
       "<tr><td>train_func_0787e_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0303044  </td></tr>\n",
       "<tr><td>train_func_0787e_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000203301</td></tr>\n",
       "<tr><td>train_func_0787e_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00173267 </td></tr>\n",
       "<tr><td>train_func_0787e_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000246187</td></tr>\n",
       "<tr><td>train_func_0787e_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0772869  </td></tr>\n",
       "<tr><td>train_func_0787e_00008</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000393541</td></tr>\n",
       "<tr><td>train_func_0787e_00009</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.00309822 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-09 12:47:00 (running for 00:00:45.14)<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 9.000: None | Iter 3.000: None | Iter 1.000: None<br>Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.79 GiB heap, 0.0/1.4 GiB objects<br>Result logdir: C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15<br>Number of trials: 10/10 (8 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00000</td><td>RUNNING </td><td>127.0.0.1:14900</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00755458 </td></tr>\n",
       "<tr><td>train_func_0787e_00001</td><td>RUNNING </td><td>127.0.0.1:22024</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000117863</td></tr>\n",
       "<tr><td>train_func_0787e_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000438003</td></tr>\n",
       "<tr><td>train_func_0787e_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0303044  </td></tr>\n",
       "<tr><td>train_func_0787e_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000203301</td></tr>\n",
       "<tr><td>train_func_0787e_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00173267 </td></tr>\n",
       "<tr><td>train_func_0787e_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000246187</td></tr>\n",
       "<tr><td>train_func_0787e_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0772869  </td></tr>\n",
       "<tr><td>train_func_0787e_00008</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000393541</td></tr>\n",
       "<tr><td>train_func_0787e_00009</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.00309822 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-09 12:47:05 (running for 00:00:50.20)<br>Memory usage on this node: 15.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 9.000: None | Iter 3.000: None | Iter 1.000: None<br>Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.79 GiB heap, 0.0/1.4 GiB objects<br>Result logdir: C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15<br>Number of trials: 10/10 (8 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00000</td><td>RUNNING </td><td>127.0.0.1:14900</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00755458 </td></tr>\n",
       "<tr><td>train_func_0787e_00001</td><td>RUNNING </td><td>127.0.0.1:22024</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000117863</td></tr>\n",
       "<tr><td>train_func_0787e_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000438003</td></tr>\n",
       "<tr><td>train_func_0787e_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0303044  </td></tr>\n",
       "<tr><td>train_func_0787e_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000203301</td></tr>\n",
       "<tr><td>train_func_0787e_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00173267 </td></tr>\n",
       "<tr><td>train_func_0787e_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000246187</td></tr>\n",
       "<tr><td>train_func_0787e_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0772869  </td></tr>\n",
       "<tr><td>train_func_0787e_00008</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000393541</td></tr>\n",
       "<tr><td>train_func_0787e_00009</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.00309822 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-09 12:47:10 (running for 00:00:55.32)<br>Memory usage on this node: 15.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 9.000: None | Iter 3.000: None | Iter 1.000: None<br>Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.79 GiB heap, 0.0/1.4 GiB objects<br>Result logdir: C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15<br>Number of trials: 10/10 (8 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00000</td><td>RUNNING </td><td>127.0.0.1:14900</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00755458 </td></tr>\n",
       "<tr><td>train_func_0787e_00001</td><td>RUNNING </td><td>127.0.0.1:22024</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000117863</td></tr>\n",
       "<tr><td>train_func_0787e_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000438003</td></tr>\n",
       "<tr><td>train_func_0787e_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0303044  </td></tr>\n",
       "<tr><td>train_func_0787e_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000203301</td></tr>\n",
       "<tr><td>train_func_0787e_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00173267 </td></tr>\n",
       "<tr><td>train_func_0787e_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000246187</td></tr>\n",
       "<tr><td>train_func_0787e_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0772869  </td></tr>\n",
       "<tr><td>train_func_0787e_00008</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000393541</td></tr>\n",
       "<tr><td>train_func_0787e_00009</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.00309822 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-09 12:47:15 (running for 00:01:00.38)<br>Memory usage on this node: 15.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 9.000: None | Iter 3.000: None | Iter 1.000: None<br>Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.79 GiB heap, 0.0/1.4 GiB objects<br>Result logdir: C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15<br>Number of trials: 10/10 (8 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00000</td><td>RUNNING </td><td>127.0.0.1:14900</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00755458 </td></tr>\n",
       "<tr><td>train_func_0787e_00001</td><td>RUNNING </td><td>127.0.0.1:22024</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000117863</td></tr>\n",
       "<tr><td>train_func_0787e_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000438003</td></tr>\n",
       "<tr><td>train_func_0787e_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0303044  </td></tr>\n",
       "<tr><td>train_func_0787e_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000203301</td></tr>\n",
       "<tr><td>train_func_0787e_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00173267 </td></tr>\n",
       "<tr><td>train_func_0787e_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000246187</td></tr>\n",
       "<tr><td>train_func_0787e_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0772869  </td></tr>\n",
       "<tr><td>train_func_0787e_00008</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000393541</td></tr>\n",
       "<tr><td>train_func_0787e_00009</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.00309822 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m 2022-07-09 12:47:16,693\tERROR function_runner.py:281 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\function_runner.py\", line 272, in run\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\function_runner.py\", line 348, in entrypoint\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return self._trainable_func(\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 462, in _resume_span\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\function_runner.py\", line 640, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\utils\\trainable.py\", line 390, in _inner\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     inner(config, checkpoint_dir=None)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\utils\\trainable.py\", line 381, in inner\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     trainable(config, **fn_kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_5568\\195199421.py\", line 71, in train_func\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_5568\\195199421.py\", line 33, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torchvision\\models\\video\\resnet.py\", line 229, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     x = self.layer1(x)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 139, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     input = module(input)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torchvision\\models\\video\\resnet.py\", line 105, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     out = self.conv1(x)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 139, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     input = module(input)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 587, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return self._conv_forward(input, self.weight, self.bias)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 582, in _conv_forward\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return F.conv3d(\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m RuntimeError: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:79] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2516582400 bytes.\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m Exception in thread Thread-3:\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\function_runner.py\", line 298, in run\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\function_runner.py\", line 272, in run\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\function_runner.py\", line 348, in entrypoint\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return self._trainable_func(\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 462, in _resume_span\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\function_runner.py\", line 640, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\utils\\trainable.py\", line 390, in _inner\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     inner(config, checkpoint_dir=None)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\utils\\trainable.py\", line 381, in inner\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     trainable(config, **fn_kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_5568\\195199421.py\", line 71, in train_func\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_5568\\195199421.py\", line 33, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torchvision\\models\\video\\resnet.py\", line 229, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     x = self.layer1(x)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 139, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     input = module(input)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torchvision\\models\\video\\resnet.py\", line 105, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     out = self.conv1(x)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 139, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     input = module(input)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 587, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return self._conv_forward(input, self.weight, self.bias)\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 582, in _conv_forward\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m     return F.conv3d(\n",
      "\u001b[2m\u001b[36m(train_func pid=22024)\u001b[0m RuntimeError: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:79] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2516582400 bytes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 12:47:19,610\tERROR trial_runner.py:876 -- Trial train_func_0787e_00001: Error processing event.\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_func_0787e_00001:\n",
      "  date: 2022-07-09_12-46-24\n",
      "  experiment_id: 0cc7d376c3af484c883fd0fcf8e64488\n",
      "  hostname: Tristens-PC\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 22024\n",
      "  timestamp: 1657388784\n",
      "  trial_id: 0787e_00001\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 12:47:20,072\tINFO trial_runner.py:803 -- starting train_func_0787e_00002\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m 2022-07-09 12:47:20,042\tINFO context.py:67 -- Exec'ing worker with command: \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\python.exe\" C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\workers/default_worker.py --node-ip-address=127.0.0.1 --node-manager-port=63550 --object-store-name=tcp://127.0.0.1:64744 --raylet-name=tcp://127.0.0.1:64150 --redis-address=None --storage=None --temp-dir=C:\\Users\\trist\\AppData\\Local\\Temp\\ray --metrics-agent-port=63803 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=127.0.0.1:63629 --redis-password=5241590000000000 --startup-token=9 --runtime-env-hash=-125176900\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.0.0)/charset_normalizer (2.0.6) doesn't match a supported version!\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m   warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.0.0)/charset_normalizer (2.0.6) doesn't match a supported version!\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m   warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-09 12:47:27 (running for 00:01:11.76)<br>Memory usage on this node: 11.3/15.6 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 9.000: None | Iter 3.000: None | Iter 1.000: None<br>Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.79 GiB heap, 0.0/1.4 GiB objects<br>Result logdir: C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15<br>Number of trials: 10/10 (1 ERROR, 7 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00000</td><td>RUNNING </td><td>127.0.0.1:14900</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00755458 </td></tr>\n",
       "<tr><td>train_func_0787e_00002</td><td>RUNNING </td><td>127.0.0.1:2980 </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000438003</td></tr>\n",
       "<tr><td>train_func_0787e_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0303044  </td></tr>\n",
       "<tr><td>train_func_0787e_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000203301</td></tr>\n",
       "<tr><td>train_func_0787e_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00173267 </td></tr>\n",
       "<tr><td>train_func_0787e_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000246187</td></tr>\n",
       "<tr><td>train_func_0787e_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0772869  </td></tr>\n",
       "<tr><td>train_func_0787e_00008</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000393541</td></tr>\n",
       "<tr><td>train_func_0787e_00009</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.00309822 </td></tr>\n",
       "<tr><td>train_func_0787e_00001</td><td>ERROR   </td><td>127.0.0.1:22024</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000117863</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00001</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15\\train_func_0787e_00001_1_batch_size=20,epochs=150,lr=0.00011786_2022-07-09_12-46-19\\error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 12:47:29,101\tWARNING tune.py:650 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-09 12:47:32 (running for 00:01:16.84)<br>Memory usage on this node: 12.6/15.6 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 9.000: None | Iter 3.000: None | Iter 1.000: None<br>Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.79 GiB heap, 0.0/1.4 GiB objects<br>Result logdir: C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15<br>Number of trials: 10/10 (1 ERROR, 7 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00000</td><td>RUNNING </td><td>127.0.0.1:14900</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00755458 </td></tr>\n",
       "<tr><td>train_func_0787e_00002</td><td>RUNNING </td><td>127.0.0.1:2980 </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000438003</td></tr>\n",
       "<tr><td>train_func_0787e_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0303044  </td></tr>\n",
       "<tr><td>train_func_0787e_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000203301</td></tr>\n",
       "<tr><td>train_func_0787e_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00173267 </td></tr>\n",
       "<tr><td>train_func_0787e_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000246187</td></tr>\n",
       "<tr><td>train_func_0787e_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0772869  </td></tr>\n",
       "<tr><td>train_func_0787e_00008</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000393541</td></tr>\n",
       "<tr><td>train_func_0787e_00009</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.00309822 </td></tr>\n",
       "<tr><td>train_func_0787e_00001</td><td>ERROR   </td><td>127.0.0.1:22024</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000117863</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00001</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15\\train_func_0787e_00001_1_batch_size=20,epochs=150,lr=0.00011786_2022-07-09_12-46-19\\error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-09 12:47:32 (running for 00:01:16.86)<br>Memory usage on this node: 12.6/15.6 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 9.000: None | Iter 3.000: None | Iter 1.000: None<br>Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.79 GiB heap, 0.0/1.4 GiB objects<br>Result logdir: C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15<br>Number of trials: 10/10 (1 ERROR, 7 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00000</td><td>RUNNING </td><td>127.0.0.1:14900</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00755458 </td></tr>\n",
       "<tr><td>train_func_0787e_00002</td><td>RUNNING </td><td>127.0.0.1:2980 </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000438003</td></tr>\n",
       "<tr><td>train_func_0787e_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0303044  </td></tr>\n",
       "<tr><td>train_func_0787e_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000203301</td></tr>\n",
       "<tr><td>train_func_0787e_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00173267 </td></tr>\n",
       "<tr><td>train_func_0787e_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.000246187</td></tr>\n",
       "<tr><td>train_func_0787e_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.0772869  </td></tr>\n",
       "<tr><td>train_func_0787e_00008</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000393541</td></tr>\n",
       "<tr><td>train_func_0787e_00009</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">0.00309822 </td></tr>\n",
       "<tr><td>train_func_0787e_00001</td><td>ERROR   </td><td>127.0.0.1:22024</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000117863</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_func_0787e_00001</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\trist\\ray_results\\train_func_2022-07-09_12-46-15\\train_func_0787e_00001_1_batch_size=20,epochs=150,lr=0.00011786_2022-07-09_12-46-19\\error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m 2022-07-09 12:48:14,710\tERROR function_runner.py:281 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\function_runner.py\", line 272, in run\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\function_runner.py\", line 348, in entrypoint\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return self._trainable_func(\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 462, in _resume_span\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\function_runner.py\", line 640, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\utils\\trainable.py\", line 390, in _inner\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     inner(config, checkpoint_dir=None)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\utils\\trainable.py\", line 381, in inner\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     trainable(config, **fn_kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_5568\\195199421.py\", line 71, in train_func\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_5568\\195199421.py\", line 33, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torchvision\\models\\video\\resnet.py\", line 229, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     x = self.layer1(x)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 139, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     input = module(input)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torchvision\\models\\video\\resnet.py\", line 105, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     out = self.conv1(x)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 139, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     input = module(input)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 587, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return self._conv_forward(input, self.weight, self.bias)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 582, in _conv_forward\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return F.conv3d(\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m RuntimeError: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:79] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2516582400 bytes.\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m Exception in thread Thread-3:\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\function_runner.py\", line 298, in run\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\function_runner.py\", line 272, in run\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\function_runner.py\", line 348, in entrypoint\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return self._trainable_func(\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 462, in _resume_span\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\function_runner.py\", line 640, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\utils\\trainable.py\", line 390, in _inner\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     inner(config, checkpoint_dir=None)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\utils\\trainable.py\", line 381, in inner\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     trainable(config, **fn_kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_5568\\195199421.py\", line 71, in train_func\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_5568\\195199421.py\", line 33, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torchvision\\models\\video\\resnet.py\", line 229, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     x = self.layer1(x)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 139, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     input = module(input)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torchvision\\models\\video\\resnet.py\", line 105, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     out = self.conv1(x)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 139, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     input = module(input)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 587, in forward\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return self._conv_forward(input, self.weight, self.bias)\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m   File \"C:\\Users\\trist\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 582, in _conv_forward\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m     return F.conv3d(\n",
      "\u001b[2m\u001b[36m(train_func pid=2980)\u001b[0m RuntimeError: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:79] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2516582400 bytes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36mimage_model.get_model\u001b[1;34m(self, X_train, y_train, X_val, y_val, epochs, batch_size)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_image_clinical_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m), strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36mimage_model.main\u001b[1;34m(self, X_train, y_train, num_samples, max_num_epochs, gpus_per_trial)\u001b[0m\n\u001b[0;32m     53\u001b[0m     result \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m     54\u001b[0m         tune\u001b[38;5;241m.\u001b[39mwith_parameters(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain_func, data\u001b[38;5;241m=\u001b[39m[id_X_train, id_y_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres]),\n\u001b[0;32m     55\u001b[0m         resources_per_trial\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:gpus_per_trial},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m         scheduler\u001b[38;5;241m=\u001b[39mscheduler\n\u001b[0;32m     61\u001b[0m     )\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mid_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_y_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mres\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresources_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mget_best_trial(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial config: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(best_trial\u001b[38;5;241m.\u001b[39mconfig))\n",
      "File \u001b[1;32m~\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\tune.py:686\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, _experiment_checkpoint_dir, queue_trials, loggers, _remote)\u001b[0m\n\u001b[0;32m    683\u001b[0m     _report_progress(runner, progress_reporter, done\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    685\u001b[0m wait_for_sync()\n\u001b[1;32m--> 686\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    688\u001b[0m incomplete_trials \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mget_trials():\n",
      "File \u001b[1;32m~\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\trial_runner.py:1382\u001b[0m, in \u001b[0;36mTrialRunner.cleanup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcleanup\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1381\u001b[0m     \u001b[38;5;124;03m\"\"\"Cleanup trials and callbacks.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1382\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1383\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_experiment_callbacks()\n",
      "File \u001b[1;32m~\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\trial_runner.py:1378\u001b[0m, in \u001b[0;36mTrialRunner.cleanup_trials\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcleanup_trials\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 1378\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\tune\\ray_trial_executor.py:747\u001b[0m, in \u001b[0;36mRayTrialExecutor.cleanup\u001b[1;34m(self, trials)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_force_trial_cleanup()\n\u001b[1;32m--> 747\u001b[0m ready, _ \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_futures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ready:\n\u001b[0;32m    749\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\_private\\client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\cs_projects\\Cancer_Project\\Cancer_ML\\env\\lib\\site-packages\\ray\\worker.py:1993\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[0;32m   1991\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[0;32m   1992\u001b[0m timeout_milliseconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m-> 1993\u001b[0m ready_ids, remaining_ids \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1999\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "File \u001b[1;32mpython\\ray\\_raylet.pyx:1401\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpython\\ray\\_raylet.pyx:167\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.get_model(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e91ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test_model(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
